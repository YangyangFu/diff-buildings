{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameter Inference\n",
    "\n",
    "This is a script for running parameter inference for a RC model based on given measurement data. \n",
    "The main purposes are:\n",
    "1. enable differentiable parameter inference based on differential programming\n",
    "2. check if GPU can be faster than CPU application\n",
    "    - on my local machine, GPU run time is thousand time slower than CPU\n",
    "    - need run more tests on Google Colab\n",
    "        - single GPU\n",
    "        - multiple TPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Limit ourselves to single-threaded jax/xla operations to avoid thrashing. See\n",
    "# https://github.com/google/jax/issues/743.\n",
    "os.environ[\"XLA_FLAGS\"] = (\"--xla_cpu_multi_thread_eigen=false \"\n",
    "                           \"intra_op_parallelism_threads=1\")\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from jax import jit, lax\n",
    "from jax import grad\n",
    "from diffrax import diffeqsolve, ODETerm, Euler, Dopri5, SaveAt, PIDController\n",
    "import optax \n",
    "import matplotlib.pyplot as plt\n",
    "import time \n",
    "import json\n",
    "from functools import partial \n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_devices = jax.local_device_count()\n",
    "print(n_devices) \n",
    "print(jax.devices())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a 4r3c model for zone temperature prediction\n",
    "```\n",
    "ODE::   xdot = Ax + Bd\n",
    "        y = Cx\n",
    "States:\n",
    "        x = [Tai, Twe, Twi]'\n",
    "Disturbances:\n",
    "        u = [Tao, qCon_i, qHVAC, qRad_e, qRad_i]'\n",
    "Output:\n",
    "        y = [Tai]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit\n",
    "def get_ABCD(Cai, Cwe, Cwi, Re, Ri, Rw, Rg):\n",
    "    A = jnp.zeros((3, 3))\n",
    "    B = jnp.zeros((3, 5))\n",
    "    C = jnp.zeros((1, 3))\n",
    "    A = A.at[0, 0].set(-1/Cai*(1/Rg+1/Ri))\n",
    "    A = A.at[0, 2].set(1/(Cai*Ri))\n",
    "    A = A.at[1, 1].set(-1/Cwe*(1/Re+1/Rw))\n",
    "    A = A.at[1, 2].set(1/(Cwe*Rw))\n",
    "    A = A.at[2, 0].set(1/(Cwi*Ri))\n",
    "    A = A.at[2, 1].set(1/(Cwi*Rw))\n",
    "    A = A.at[2, 2].set(-1/Cwi*(1/Rw+1/Ri))\n",
    "\n",
    "    B = B.at[0, 0].set(1/(Cai*Rg))\n",
    "    B = B.at[0, 1].set(1/Cai)\n",
    "    B = B.at[0, 2].set(1/Cai)\n",
    "    B = B.at[1, 0].set(1/(Cwe*Re))\n",
    "    B = B.at[1, 3].set(1/Cwe)\n",
    "    B = B.at[2, 4].set(1/Cwi)\n",
    "\n",
    "    C = C.at[0, 0].set(1)\n",
    "\n",
    "    D = 0\n",
    "\n",
    "    return A, B, C, D\n",
    "\n",
    "@jit\n",
    "def zone_state_space(t, x, A, B, d):\n",
    "    x = x.reshape(-1, 1)\n",
    "    d = d.reshape(-1, 1)\n",
    "    dx = jnp.matmul(A, x) + jnp.matmul(B, d)\n",
    "    dx = dx.reshape(-1)\n",
    "\n",
    "    return dx"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Simulation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@partial(jit, static_argnums=(0, 1, 2, 3,))\n",
    "def forward(func, ts, te, dt, x0, solver, args):\n",
    "    # unpack args\n",
    "    A, B, d = args\n",
    "\n",
    "    # ode formulation\n",
    "    term = ODETerm(func)\n",
    "\n",
    "    # initial step\n",
    "    t = ts\n",
    "    tnext = t + dt\n",
    "    dprev = d[0, :]\n",
    "    args = (A, B, dprev)\n",
    "    state = solver.init(term, t, tnext, x0, args)\n",
    "\n",
    "    # initialize output\n",
    "    #t_all = [t]\n",
    "    #x_all = [x0]\n",
    "\n",
    "    # main loop\n",
    "    i = 0\n",
    "    #x = x0\n",
    "\n",
    "    # jit-ed scan to replace while loop\n",
    "#    cond_func = lambda t: t < te\n",
    "    def step_at_t(carryover, t, term, dt, te, A, B, d):\n",
    "        # the lax.scannable function to computer ODE/DAE systems\n",
    "        x = carryover[0]\n",
    "        state = carryover[1]\n",
    "        i = carryover[2]\n",
    "        args = (A, B, d[i, :])\n",
    "        tnext = jnp.minimum(t + dt, te)\n",
    "\n",
    "        xnext, _, _, state, _ = solver.step(\n",
    "            term, t, tnext, x, args, state, made_jump=False)\n",
    "        i += 1\n",
    "\n",
    "        return (xnext, state, i), x\n",
    "\n",
    "    carryover_init = (x0, state, i)\n",
    "    step_func = partial(step_at_t, term=term, dt=dt, te=te, A=A, B=B, d=d)\n",
    "    time_steps = np.arange(ts, te+1, dt)\n",
    "    carryover_final, x_all = lax.scan(\n",
    "        step_func, init=carryover_init, xs=time_steps)\n",
    "\n",
    "    return time_steps, x_all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data - 1-min sampling rate\n",
    "data = pd.read_csv('./data/disturbance_1min.csv', index_col=[0])\n",
    "index = range(0, len(data)*60, 60)\n",
    "data.index = index\n",
    "\n",
    "# sample every hour\n",
    "dt = 3600\n",
    "data = data.groupby([data.index // dt]).mean()\n",
    "n = len(data)\n",
    "\n",
    "# split training and testing\n",
    "ratio = 0.75\n",
    "n_train = int(len(data)*ratio)\n",
    "print(n_train)\n",
    "data_train = data.iloc[:n_train, :]\n",
    "data_test = data.iloc[n_train:, :]\n",
    "\n",
    "# define training parameters \n",
    "ts = 0\n",
    "te = ts + n_train*dt\n",
    "solver = Euler()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward steps\n",
    "f = lambda t, x, args: zone_state_space(t, x, *args)#args[0], args[1], args[2]) \n",
    "def forward_parameters(p, x, ts, te, dt, solver, d):\n",
    "    \"\"\"\n",
    "    p is [Cai, Cwe, Cwi, Re, Ri, Rw, Rg, Twe0, Twi0]\n",
    "    x is Tz0\n",
    "    \"\"\"\n",
    "    Cai, Cwe, Cwi, Re, Ri, Rw, Rg, Twe0, Twi0 = p['rc']\n",
    "    A, B, C, D = get_ABCD(Cai, Cwe, Cwi, Re, Ri, Rw, Rg)\n",
    "    args = (A, B, d)\n",
    "\n",
    "    # intial point\n",
    "    x0 = jnp.array([x, Twe0, Twi0])\n",
    "\n",
    "    # forward calculation\n",
    "    t, x = forward(f, ts, te, dt, x0, solver, args)\n",
    "\n",
    "    return t, x \n",
    "\n",
    "model = lambda p,x: forward_parameters(p, x, ts, te, dt, solver, d)\n",
    "model = jit(model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "@jit\n",
    "def loss_fcn(p, x, y_true, p_lb, p_ub):\n",
    "    _, y_pred = model(p, x)\n",
    "    loss = jnp.mean((y_pred[1:,0] - y_true)**2)\n",
    "\n",
    "    penalty = jnp.sum(jax.nn.relu(p['rc'] - p_ub) + jax.nn.relu(p_lb - p['rc']))\n",
    "\n",
    "    return loss + penalty\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = data_train.values[:,:5]\n",
    "y_train = data_train.values[:,5]\n",
    "d = jax.device_put(d)\n",
    "y_train=jax.device_put(y_train)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fit(data, n_epochs, params: optax.Params, optimizer: optax.GradientTransformation, p_lb, p_ub) -> optax.Params:\n",
    "    # initialize params\n",
    "    states = optimizer.init(params)\n",
    "    x, y = data \n",
    "\n",
    "    @jit\n",
    "    def step(params, states, x, y, p_lb, p_ub):\n",
    "        loss, grads = jax.value_and_grad(loss_fcn)(params, x, y, p_lb, p_ub)\n",
    "        updates, states = optimizer.update(grads, states, params)\n",
    "        params = optax.apply_updates(params, updates)\n",
    "\n",
    "        return params, states, loss, grads\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        params, states, loss, grads = step(params, states, x, y, p_lb, p_ub)\n",
    "        if epoch % 1000 == 0:\n",
    "            print(f'epoch {epoch}, training loss: {loss}')\n",
    "            #print(grads['rc'].max(), grads['rc'].min())\n",
    "\n",
    "    return params\n",
    "\n",
    "## Run optimization for inference\n",
    "# parameter settings\n",
    "p_lb = jnp.array([1.0E3, 1.0E4, 1.0E5, 1.0, 1E-02, 1.0, 1.0E-1, 20.0, 20.0])\n",
    "p_ub = jnp.array([1.0E5, 1.0E6, 1.0E7, 10., 10., 100., 10., 35.0, 30.0])\n",
    "\n",
    "#p0 = jnp.array([9998.0869140625, 99998.0859375, 999999.5625, 9.94130802154541, 0.6232420802116394, 1.1442776918411255, 5.741048812866211, 34.82638931274414, 26.184139251708984])\n",
    "\n",
    "p0 = p_ub\n",
    "x0 = jax.device_put(y_train[0])\n",
    "print(p0, x0)\n",
    "print(loss_fcn({'rc':p0}, x0, y_train, p_lb, p_ub))\n",
    "\n",
    "n_epochs = 100000\n",
    "schedule = optax.exponential_decay(\n",
    "    init_value = 0.1, \n",
    "    transition_steps = 1000, \n",
    "    decay_rate = 0.99, \n",
    "    transition_begin=0, \n",
    "    staircase=False, \n",
    "    end_value=1e-05\n",
    ")\n",
    "optimizer = optax.chain(\n",
    "    optax.adabelief(learning_rate = schedule)\n",
    ")\n",
    "\n",
    "initial_params = {'rc': p0}\n",
    "s = time.time()\n",
    "params = fit((x0, y_train), n_epochs, initial_params, optimizer, p_lb, p_ub)\n",
    "e = time.time()\n",
    "print(f\"execution time is: {e-s} seconds !\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# forward simulation with infered parameters for the whole data set\n",
    "ts = 0\n",
    "te = ts + n*dt\n",
    "d = data.values[:, :5]\n",
    "y = data.values[:, 5]\n",
    "forward_ts = time.time()\n",
    "model = lambda p,x: forward_parameters(p, x, ts, te, dt, solver, d)\n",
    "t_pred, ys_pred = model(params, x0)\n",
    "forward_te = time.time()\n",
    "print(f\"single forward simulation costs {forward_te-forward_ts} s!\")\n",
    "y_pred = ys_pred[:,0]\n",
    "\n",
    "print(t_pred.shape, y_pred.shape)\n",
    "print(y.shape)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(y, 'b-', label='Target')\n",
    "plt.plot(y_pred, 'r-', label=\"Prediction\")\n",
    "plt.ylabel('Temperature (C)')\n",
    "plt.legend()\n",
    "plt.savefig('parameter_inference.png')\n",
    "\n",
    "# save the parameters\n",
    "params_tolist = [float(p) for p in params['rc']]\n",
    "with open('zone_coefficients.json', 'w') as f:\n",
    "    json.dump(params_tolist,f)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
