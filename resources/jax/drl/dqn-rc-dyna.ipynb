{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class QNetwork(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(2)(x)\n",
    "        return x\n",
    "\n",
    "class EnvModel(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(3)(x)  # 3 outputs: 2 states [Tz for next step and power for next step] (although we have simple relationship between power and control action), and reward\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import env\n",
    "# RC model parameters\n",
    "rc_params = [6.9789902e+03, 2.1591113e+04, 1.8807944e+05, 3.4490612e+00, 4.9556872e-01, 9.8289281e-02, 4.6257420e+00]\n",
    "x0 = np.array([20, 35.8, 26.])\n",
    "x_high = np.array([40., 80., 40.])\n",
    "x_low = np.array([10., 10., 10.])\n",
    "n_actions = 101\n",
    "u_high = [0]\n",
    "u_low = [-10.0] # -12\n",
    "\n",
    "# load disturbances\n",
    "file_path = os.path.abspath('')\n",
    "parent_path = os.path.dirname(file_path)\n",
    "data_path = os.path.join(parent_path, 'data/disturbance_1min.csv')\n",
    "data = pd.read_csv(data_path, index_col=[0])\n",
    "# assign time index\n",
    "t_base = 181*24*3600 # 7/1\n",
    "n = len(data)\n",
    "index = range(t_base, t_base + n*60, 60)\n",
    "data.index = index\n",
    "\n",
    "# sample\n",
    "dt = 900\n",
    "data = data.groupby([data.index // dt]).mean()\n",
    "index_dt = range(t_base, t_base + len(data)*dt, dt)\n",
    "data.index = index_dt \n",
    "\n",
    "# get disturbances for lssm\n",
    "t_d = index_dt\n",
    "disturbance_names = ['out_temp', 'qint_lump', 'qwin_lump', 'qradin_lump']\n",
    "disturbance = data[disturbance_names].values\n",
    "\n",
    "# RC Gym envionment\n",
    "ts = 195*24*3600\n",
    "ndays = 7\n",
    "te = ndays*24*3600 + ts\n",
    "weights = [100., 1., 0.] # for energy cost, dT, du\n",
    "\n",
    "env = gym.make(\"R4C3Discrete-v0\",\n",
    "            rc_params = rc_params,\n",
    "            x0 = x0,\n",
    "            x_high = x_high,\n",
    "            x_low = x_low,\n",
    "            n_actions = n_actions,\n",
    "            u_high = u_high,\n",
    "            u_low = u_low,\n",
    "            disturbances = (t_d, disturbance),\n",
    "            ts = ts,\n",
    "            te = te,\n",
    "            dt = dt,\n",
    "            weights = weights).env\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 106\u001b[0m\n\u001b[1;32m    103\u001b[0m action_batch \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39marray([a \u001b[39mfor\u001b[39;00m (_, a, _, _, _) \u001b[39min\u001b[39;00m batch])\n\u001b[1;32m    105\u001b[0m state_action_batch \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mconcatenate([state_batch, action_batch[:, np\u001b[39m.\u001b[39mnewaxis]], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 106\u001b[0m predictions \u001b[39m=\u001b[39m env_model\u001b[39m.\u001b[39;49mapply(env_model_params, state_action_batch)\n\u001b[1;32m    108\u001b[0m \u001b[39m# replace Tz and power with predicted values for the next state\u001b[39;00m\n\u001b[1;32m    109\u001b[0m Tz_next \u001b[39m=\u001b[39m predictions[:, \u001b[39m0\u001b[39m]\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:1467\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1465\u001b[0m   method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m\n\u001b[1;32m   1466\u001b[0m method \u001b[39m=\u001b[39m _get_unbound_fn(method)\n\u001b[0;32m-> 1467\u001b[0m \u001b[39mreturn\u001b[39;00m apply(\n\u001b[1;32m   1468\u001b[0m     method, \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1469\u001b[0m     mutable\u001b[39m=\u001b[39;49mmutable,\n\u001b[1;32m   1470\u001b[0m     capture_intermediates\u001b[39m=\u001b[39;49mcapture_intermediates,\n\u001b[1;32m   1471\u001b[0m )(variables, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, rngs\u001b[39m=\u001b[39;49mrngs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/core/scope.py:933\u001b[0m, in \u001b[0;36mapply.<locals>.wrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mApplyScopeInvalidVariablesStructureError(variables)\n\u001b[1;32m    931\u001b[0m \u001b[39mwith\u001b[39;00m bind(variables, rngs\u001b[39m=\u001b[39mrngs, mutable\u001b[39m=\u001b[39mmutable,\n\u001b[1;32m    932\u001b[0m           flags\u001b[39m=\u001b[39mflags)\u001b[39m.\u001b[39mtemporary() \u001b[39mas\u001b[39;00m root:\n\u001b[0;32m--> 933\u001b[0m   y \u001b[39m=\u001b[39m fn(root, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m mutable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[39mreturn\u001b[39;00m y, root\u001b[39m.\u001b[39mmutable_variables()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:2038\u001b[0m, in \u001b[0;36mapply.<locals>.scope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m _context\u001b[39m.\u001b[39mcapture_stack\u001b[39m.\u001b[39mappend(capture_intermediates)\n\u001b[1;32m   2037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2038\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(module\u001b[39m.\u001b[39;49mclone(parent\u001b[39m=\u001b[39;49mscope), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2039\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2040\u001b[0m   _context\u001b[39m.\u001b[39mcapture_stack\u001b[39m.\u001b[39mpop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:424\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    423\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 424\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:842\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    841\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 842\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[31], line 22\u001b[0m, in \u001b[0;36mEnvModel.__call__\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     20\u001b[0m x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mDense(\u001b[39m256\u001b[39m)(x)\n\u001b[1;32m     21\u001b[0m x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mrelu(x)\n\u001b[0;32m---> 22\u001b[0m x \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39;49mDense(\u001b[39m3\u001b[39;49m)(x)  \u001b[39m# 3 outputs: 2 states [Tz for next step and power for next step] (although we have simple relationship between power and control action), and reward\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:424\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    423\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 424\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:842\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    841\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 842\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/linear.py:196\u001b[0m, in \u001b[0;36mDense.__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[39m@compact\u001b[39m\n\u001b[1;32m    187\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, inputs: Array) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Array:\n\u001b[1;32m    188\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Applies a linear transformation to the inputs along the last dimension.\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \n\u001b[1;32m    190\u001b[0m \u001b[39m  Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[39m    The transformed input.\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m   kernel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam(\u001b[39m'\u001b[39;49m\u001b[39mkernel\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    197\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mkernel_init,\n\u001b[1;32m    198\u001b[0m                       (jnp\u001b[39m.\u001b[39;49mshape(inputs)[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m], \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures),\n\u001b[1;32m    199\u001b[0m                       \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam_dtype)\n\u001b[1;32m    200\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39muse_bias:\n\u001b[1;32m    201\u001b[0m     bias \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\u001b[39m'\u001b[39m\u001b[39mbias\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbias_init, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures,),\n\u001b[1;32m    202\u001b[0m                       \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam_dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:1219\u001b[0m, in \u001b[0;36mModule.param\u001b[0;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m   1217\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mNameInUseError(\u001b[39m'\u001b[39m\u001b[39mparam\u001b[39m\u001b[39m'\u001b[39m, name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1218\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscope\u001b[39m.\u001b[39;49mparam(name, init_fn, \u001b[39m*\u001b[39;49minit_args, unbox\u001b[39m=\u001b[39;49munbox)\n\u001b[1;32m   1220\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mchildren[name] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1221\u001b[0m \u001b[39mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/core/scope.py:827\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m    821\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m, name)\n\u001b[1;32m    822\u001b[0m \u001b[39m# Validate that the shape of the init_fn output is the same as the shape\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m# of the existing parameter. This is to make sure that the hparams set up\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# in a Flax Module match the shapes coming in during apply, and if not,\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[39m# catch it with an error message.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39m# NOTE: We could consider moving this to `self.`\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m abs_value \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49meval_shape(\u001b[39mlambda\u001b[39;49;00m rng: init_fn(rng, \u001b[39m*\u001b[39;49minit_args), abs_rng)\n\u001b[1;32m    828\u001b[0m abs_value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(abs_value)\n\u001b[1;32m    829\u001b[0m value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/api.py:3320\u001b[0m, in \u001b[0;36meval_shape\u001b[0;34m(fun, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3318\u001b[0m wrapped_fun, out_tree \u001b[39m=\u001b[39m flatten_fun(lu\u001b[39m.\u001b[39mwrap_init(fun), in_tree)\n\u001b[1;32m   3319\u001b[0m debug_info \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39mdebug_info(fun, in_tree, \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39meval_shape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 3320\u001b[0m out \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39;49mabstract_eval_fun(wrapped_fun\u001b[39m.\u001b[39;49mcall_wrapped,\n\u001b[1;32m   3321\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(shaped_abstractify, args_flat),\n\u001b[1;32m   3322\u001b[0m                            debug_info\u001b[39m=\u001b[39;49mdebug_info)\n\u001b[1;32m   3323\u001b[0m out \u001b[39m=\u001b[39m [ShapeDtypeStruct(x\u001b[39m.\u001b[39mshape, x\u001b[39m.\u001b[39mdtype, x\u001b[39m.\u001b[39mnamed_shape) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m out]\n\u001b[1;32m   3324\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(out_tree(), out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:663\u001b[0m, in \u001b[0;36mabstract_eval_fun\u001b[0;34m(fun, debug_info, *avals, **params)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mabstract_eval_fun\u001b[39m(fun, \u001b[39m*\u001b[39mavals, debug_info\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 663\u001b[0m   _, avals_out, _ \u001b[39m=\u001b[39m trace_to_jaxpr_dynamic(\n\u001b[1;32m    664\u001b[0m       lu\u001b[39m.\u001b[39;49mwrap_init(fun, params), avals, debug_info)\n\u001b[1;32m    665\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(aval, AbstractValue) \u001b[39mfor\u001b[39;00m aval \u001b[39min\u001b[39;00m avals_out)\n\u001b[1;32m    666\u001b[0m   \u001b[39mreturn\u001b[39;00m avals_out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1989\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, debug_info, keep_inputs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m \u001b[39mwith\u001b[39;00m core\u001b[39m.\u001b[39mnew_main(DynamicJaxprTrace, dynamic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m main:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m   main\u001b[39m.\u001b[39mjaxpr_stack \u001b[39m=\u001b[39m ()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m   jaxpr, out_avals, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic(\n\u001b[1;32m   1990\u001b[0m     fun, main, in_avals, keep_inputs\u001b[39m=\u001b[39;49mkeep_inputs, debug_info\u001b[39m=\u001b[39;49mdebug_info)\n\u001b[1;32m   1991\u001b[0m   \u001b[39mdel\u001b[39;00m main, fun\n\u001b[1;32m   1992\u001b[0m \u001b[39mreturn\u001b[39;00m jaxpr, out_avals, consts\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:2006\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals, keep_inputs, debug_info)\u001b[0m\n\u001b[1;32m   2004\u001b[0m in_tracers \u001b[39m=\u001b[39m _input_type_to_tracers(trace\u001b[39m.\u001b[39mnew_arg, in_avals)\n\u001b[1;32m   2005\u001b[0m in_tracers_ \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t, keep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(in_tracers, keep_inputs) \u001b[39mif\u001b[39;00m keep]\n\u001b[0;32m-> 2006\u001b[0m ans \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39;49mcall_wrapped(\u001b[39m*\u001b[39;49min_tracers_)\n\u001b[1;32m   2007\u001b[0m out_tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(trace\u001b[39m.\u001b[39mfull_raise, ans)\n\u001b[1;32m   2008\u001b[0m jaxpr, consts \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mto_jaxpr(out_tracers)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/linear_util.py:165\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/linear_util.py:165\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/core/scope.py:827\u001b[0m, in \u001b[0;36mScope.param.<locals>.<lambda>\u001b[0;34m(rng)\u001b[0m\n\u001b[1;32m    821\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m, name)\n\u001b[1;32m    822\u001b[0m \u001b[39m# Validate that the shape of the init_fn output is the same as the shape\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m# of the existing parameter. This is to make sure that the hparams set up\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# in a Flax Module match the shapes coming in during apply, and if not,\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[39m# catch it with an error message.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39m# NOTE: We could consider moving this to `self.`\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m abs_value \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39meval_shape(\u001b[39mlambda\u001b[39;00m rng: init_fn(rng, \u001b[39m*\u001b[39;49minit_args), abs_rng)\n\u001b[1;32m    828\u001b[0m abs_value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(abs_value)\n\u001b[1;32m    829\u001b[0m value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/nn/initializers.py:282\u001b[0m, in \u001b[0;36mvariance_scaling.<locals>.init\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m jnp\u001b[39m.\u001b[39missubdtype(dtype, jnp\u001b[39m.\u001b[39mfloating):\n\u001b[1;32m    280\u001b[0m   \u001b[39m# constant is stddev of standard normal truncated to (-2, 2)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m   stddev \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39msqrt(variance) \u001b[39m/\u001b[39m jnp\u001b[39m.\u001b[39marray(\u001b[39m.87962566103423978\u001b[39m, dtype)\n\u001b[0;32m--> 282\u001b[0m   \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39;49mtruncated_normal(key, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, named_shape, dtype) \u001b[39m*\u001b[39m stddev\n\u001b[1;32m    283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m   \u001b[39m# constant is stddev of complex standard normal truncated to 2\u001b[39;00m\n\u001b[1;32m    285\u001b[0m   stddev \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39msqrt(variance) \u001b[39m/\u001b[39m jnp\u001b[39m.\u001b[39marray(\u001b[39m.95311164380491208\u001b[39m, dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/random.py:695\u001b[0m, in \u001b[0;36mtruncated_normal\u001b[0;34m(key, lower, upper, shape, dtype)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m   shape \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mas_named_shape(shape)\n\u001b[0;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m _truncated_normal(key, lower, upper, shape, dtype)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/api.py:698\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(execute(\u001b[39m*\u001b[39margs_flat))\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(\n\u001b[0;32m--> 698\u001b[0m       top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params))\n\u001b[1;32m    699\u001b[0m out_pytree_def \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m    700\u001b[0m out \u001b[39m=\u001b[39m tree_unflatten(out_pytree_def, out_flat)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1752\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.process_call\u001b[0;34m(self, call_primitive, f, explicit_tracers, params)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     jaxpr, out_type, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic2_memoized(\n\u001b[1;32m   1750\u001b[0m         f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain, call_primitive\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mval\n\u001b[1;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m params\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 1752\u001b[0m   \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49meval_jaxpr(jaxpr, consts, \u001b[39m*\u001b[39;49min_tracers)\n\u001b[1;32m   1753\u001b[0m source_info \u001b[39m=\u001b[39m source_info_util\u001b[39m.\u001b[39mcurrent()\n\u001b[1;32m   1754\u001b[0m out_tracers \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:409\u001b[0m, in \u001b[0;36meval_jaxpr\u001b[0;34m(jaxpr, consts, *args)\u001b[0m\n\u001b[1;32m    407\u001b[0m name_stack \u001b[39m=\u001b[39m source_info_util\u001b[39m.\u001b[39mcurrent_name_stack() \u001b[39m+\u001b[39m eqn\u001b[39m.\u001b[39msource_info\u001b[39m.\u001b[39mname_stack\n\u001b[1;32m    408\u001b[0m \u001b[39mwith\u001b[39;00m source_info_util\u001b[39m.\u001b[39muser_context(eqn\u001b[39m.\u001b[39msource_info\u001b[39m.\u001b[39mtraceback, name_stack\u001b[39m=\u001b[39mname_stack):\n\u001b[0;32m--> 409\u001b[0m   ans \u001b[39m=\u001b[39m eqn\u001b[39m.\u001b[39;49mprimitive\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49msubfuns, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(read, eqn\u001b[39m.\u001b[39;49minvars), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbind_params)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m eqn\u001b[39m.\u001b[39mprimitive\u001b[39m.\u001b[39mmultiple_results:\n\u001b[1;32m    411\u001b[0m   \u001b[39mmap\u001b[39m(write, eqn\u001b[39m.\u001b[39moutvars, ans)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:343\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    341\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    342\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:346\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 346\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mprocess_primitive(\u001b[39mself\u001b[39m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    347\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/util.py:78\u001b[0m, in \u001b[0;36msafe_map\u001b[0;34m(f, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m     77\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(arg) \u001b[39m==\u001b[39m n, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlength mismatch: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m,\u001b[39m \u001b[39margs))\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:436\u001b[0m, in \u001b[0;36mTrace.full_raise\u001b[0;34m(self, val)\u001b[0m\n\u001b[1;32m    434\u001b[0m   val \u001b[39m=\u001b[39m val\u001b[39m.\u001b[39mdimension_as_value()\n\u001b[1;32m    435\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(val, Tracer):\n\u001b[0;32m--> 436\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpure(val)\n\u001b[1;32m    437\u001b[0m val\u001b[39m.\u001b[39m_assert_live()\n\u001b[1;32m    438\u001b[0m level \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlevel\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1665\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.new_const\u001b[0;34m(self, c)\u001b[0m\n\u001b[1;32m   1663\u001b[0m tracer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39mconstid_to_tracer\u001b[39m.\u001b[39mget(\u001b[39mid\u001b[39m(c))\n\u001b[1;32m   1664\u001b[0m \u001b[39mif\u001b[39;00m tracer \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1665\u001b[0m   aval \u001b[39m=\u001b[39m raise_to_shaped(get_aval(c), weak_type\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mis_weakly_typed(c))\n\u001b[1;32m   1666\u001b[0m   tracer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_new_const(aval, c)\n\u001b[1;32m   1667\u001b[0m \u001b[39mreturn\u001b[39;00m tracer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:1269\u001b[0m, in \u001b[0;36mget_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1267\u001b[0m   \u001b[39mreturn\u001b[39;00m x\u001b[39m.\u001b[39maval\n\u001b[1;32m   1268\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1269\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_aval(x)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:1258\u001b[0m, in \u001b[0;36mconcrete_aval\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   1256\u001b[0m \u001b[39mfor\u001b[39;00m typ \u001b[39min\u001b[39;00m \u001b[39mtype\u001b[39m(x)\u001b[39m.\u001b[39m\u001b[39m__mro__\u001b[39m:\n\u001b[1;32m   1257\u001b[0m   handler \u001b[39m=\u001b[39m pytype_aval_mappings\u001b[39m.\u001b[39mget(typ)\n\u001b[0;32m-> 1258\u001b[0m   \u001b[39mif\u001b[39;00m handler: \u001b[39mreturn\u001b[39;00m handler(x)\n\u001b[1;32m   1259\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(x, \u001b[39m'\u001b[39m\u001b[39m__jax_array__\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[1;32m   1260\u001b[0m   \u001b[39mreturn\u001b[39;00m concrete_aval(x\u001b[39m.\u001b[39m__jax_array__())\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/abstract_arrays.py:53\u001b[0m, in \u001b[0;36mcanonical_concrete_aval\u001b[0;34m(val, weak_type)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcanonical_concrete_aval\u001b[39m(val, weak_type\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m---> 53\u001b[0m   \u001b[39mreturn\u001b[39;00m ConcreteArray(dtypes\u001b[39m.\u001b[39;49mcanonicalize_dtype(np\u001b[39m.\u001b[39;49mresult_type(val)), val,\n\u001b[1;32m     54\u001b[0m                        weak_type\u001b[39m=\u001b[39;49mweak_type)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:1487\u001b[0m, in \u001b[0;36mConcreteArray.__init__\u001b[0;34m(self, dtype, val, weak_type)\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m(\n\u001b[1;32m   1484\u001b[0m     np\u001b[39m.\u001b[39mshape(val), dtype,\n\u001b[1;32m   1485\u001b[0m     weak_type\u001b[39m=\u001b[39mdtypes\u001b[39m.\u001b[39mis_weakly_typed(val) \u001b[39mif\u001b[39;00m weak_type \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m weak_type)\n\u001b[1;32m   1486\u001b[0m \u001b[39m# Note: canonicalized self.dtype doesn't necessarily match self.val\u001b[39;00m\n\u001b[0;32m-> 1487\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m==\u001b[39m dtypes\u001b[39m.\u001b[39mcanonicalize_dtype(np\u001b[39m.\u001b[39;49mresult_type(val)), (val, dtype)\n\u001b[1;32m   1488\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mval \u001b[39m=\u001b[39m val\n\u001b[1;32m   1489\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdtype \u001b[39m!=\u001b[39m np\u001b[39m.\u001b[39mdtype(\u001b[39m'\u001b[39m\u001b[39mO\u001b[39m\u001b[39m'\u001b[39m), val\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(41)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.99\n",
    "episodes = 500\n",
    "batch_size = 64\n",
    "planning_steps = 5\n",
    "\n",
    "q_network = QNetwork()\n",
    "env_model = EnvModel()\n",
    "\n",
    "params = q_network.init(jax.random.PRNGKey(0), jnp.zeros((state_dim,)))\n",
    "env_model_params = env_model.init(jax.random.PRNGKey(1), jnp.zeros((state_dim + 1,)))\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "env_model_optimizer = optax.adam(learning_rate)\n",
    "\n",
    "opt_state = optimizer.init(params)\n",
    "env_model_opt_state = env_model_optimizer.init(env_model_params)\n",
    "\n",
    "@jax.jit\n",
    "def q_learning_update(params, opt_state, state, action, reward, next_state, done):\n",
    "    def loss_fn(params):\n",
    "        q_values = q_network.apply(params, state)\n",
    "        next_q_values = q_network.apply(params, next_state)\n",
    "        target = reward + gamma * jnp.max(next_q_values, axis=1) * (1 - done)\n",
    "        loss = jnp.mean((q_values[jnp.arange(q_values.shape[0]), action] - target) ** 2)\n",
    "        return loss\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state\n",
    "\n",
    "# env model update \n",
    "@jax.jit\n",
    "def env_model_update(env_model_params, env_model_opt_state, state, action, next_state, reward):\n",
    "\n",
    "    def env_model_loss_fn(env_model_params):\n",
    "\n",
    "        state_action = jnp.hstack([state, action.reshape(-1,1)])#, axis=1\n",
    "        # predictions of Tz and Power\n",
    "        predictions = env_model.apply(env_model_params, state_action)\n",
    "        # target is next Tz and power\n",
    "        Tz_target = next_state[:,1]\n",
    "        power_target = next_state[:,4]\n",
    "        \n",
    "        target = jnp.stack([Tz_target, power_target, reward], axis=1)\n",
    "        print(target.shape, predictions.shape)\n",
    "        print(\"in model update\")\n",
    "        env_model_loss = jnp.mean(jnp.square(predictions - target))\n",
    "        return env_model_loss\n",
    "\n",
    "    env_model_loss, env_model_grads = jax.value_and_grad(env_model_loss_fn)(env_model_params)\n",
    "    env_model_updates, env_model_opt_state = env_model_optimizer.update(env_model_grads, env_model_opt_state)\n",
    "    env_model_params = optax.apply_updates(env_model_params, env_model_updates)\n",
    "    return env_model_params, env_model_opt_state\n",
    "\n",
    "memory = []\n",
    "reward_history = []\n",
    "reward_threshold=175 # env.spec.reward_threshold\n",
    "solved_window = 100\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, _ = env.reset(seed=1)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_in_episode = 0\n",
    "\n",
    "    while not done:\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            q_values = q_network.apply(params, jnp.expand_dims(jnp.array(state), axis=0))\n",
    "            action = jnp.argmax(q_values).item()\n",
    "\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        memory.append((state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        step_in_episode += 1\n",
    "\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "\n",
    "            state_batch = jnp.array([s for (s, _, _, _, _) in batch])\n",
    "            action_batch = jnp.array([a for (_, a, _, _, _) in batch])\n",
    "            reward_batch = jnp.array([r for (_, _, r, _, _) in batch])\n",
    "            next_state_batch = jnp.array([ns for (_, _, _, ns, _) in batch])\n",
    "            done_batch = jnp.array([d for (_, _, _, _, d) in batch], dtype=jnp.float32)\n",
    "\n",
    "            params, opt_state = q_learning_update(params, opt_state, state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
    "            env_model_params, env_model_opt_state = env_model_update(env_model_params, env_model_opt_state, state_batch, action_batch, next_state_batch, reward_batch)\n",
    "\n",
    "            for _ in range(planning_steps):\n",
    "                planning_batch = random.sample(memory, batch_size)\n",
    "\n",
    "                state_batch = jnp.array([s for (s, _, _, _, _) in planning_batch])\n",
    "                action_batch = jnp.array([a for (_, a, _, _, _) in batch])\n",
    "\n",
    "                state_action_batch = jnp.concatenate([state_batch, action_batch[:, np.newaxis]], axis=1)\n",
    "                predictions = env_model.apply(env_model_params, state_action_batch)\n",
    "\n",
    "                # replace Tz and power with predicted values for the next state\n",
    "                Tz_next = predictions[:, 0]\n",
    "                power_next = predictions[:, 1]\n",
    "                next_state_batch = jnp.concatenate([Tz_next[:, np.newaxis], next_state_batch[:, 1:3], power_next[:, np.newaxis], next_state_batch[:, 4:]], axis=1)\n",
    "                reward_batch = predictions[:, 2]\n",
    "                done_batch = jnp.full(reward_batch.shape, False, dtype=jnp.float32)\n",
    "                #done_batch = (jnp.abs(jnp.sum(next_state_batch - state_batch, axis=1)) > 0.5).astype(jnp.float32)\n",
    "\n",
    "                params, opt_state = q_learning_update(params, opt_state, state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
    "        \n",
    "        # episode stopping: NOT IMPLEMENTED.\n",
    "\n",
    "    epsilon = max(epsilon * epsilon_decay, 0.01)\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    # outputs\n",
    "    reward_history.append(total_reward)\n",
    "\n",
    "    # stop training if average reward reaches requirement\n",
    "    # Calculate the average reward over the last 'solved_window' episodes\n",
    "    if episode >= solved_window:\n",
    "        avg_reward = np.mean(reward_history[-solved_window:])\n",
    "        print(f'Episode: {episode}, Average Reward: {avg_reward}')\n",
    "\n",
    "        if avg_reward >= reward_threshold:\n",
    "            print(f\"R4C3Discrete-v0 solved in {episode} episodes!\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the historical rewards\n",
    "plt.plot(reward_history)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Historical Rewards for CartPole-v1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training \n",
    "def plot_moving_average_reward(episode_rewards, window_size=100):\n",
    "    cumsum_rewards = np.cumsum(episode_rewards)\n",
    "    moving_avg_rewards = (cumsum_rewards[window_size:] - cumsum_rewards[:-window_size]) / window_size\n",
    "\n",
    "    plt.plot(moving_avg_rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Moving Average Reward')\n",
    "    plt.title('Moving Average Reward over Episodes')\n",
    "    plt.show()\n",
    "\n",
    "plot_moving_average_reward(reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a virtual display for rendering in docker\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "# Test the trained agent\n",
    "\n",
    "print(\"\\nTesting the trained agent...\")\n",
    "env = gym.make(\"CartPole-v1\",render_mode='rgb_array').env\n",
    "state, _ = env.reset()\n",
    "state = jnp.array(state, dtype=jnp.float32)\n",
    "\n",
    "total_reward = 0\n",
    "done = False\n",
    "pre_screen = env.render()\n",
    "step_in_episode = 0\n",
    "\n",
    "while not done:\n",
    "    q_values = q_network.apply(params, jnp.expand_dims(jnp.array(state), axis=0))\n",
    "    action = jnp.argmax(q_values).item()\n",
    "    #action = agent.act(state)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "    next_state = jnp.array(next_state, dtype=jnp.float32)\n",
    "    screen = env.render()\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "    step_in_episode += 1\n",
    "\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "\n",
    "    # check if the max_episode_steps are met. if so, terminate this episode\n",
    "    if step_in_episode >= max_episode_steps:\n",
    "        print(f\"Agent reached max_episode_steps in test.\")\n",
    "        break\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    \n",
    "print(f\"Total Reward: {total_reward}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pre_screen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
