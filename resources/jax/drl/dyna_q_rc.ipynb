{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- initialize Q(s,a) and Model(s,a)\n",
    "- Loop forever:\n",
    "  - S <- current nonterminal state\n",
    "  - A <- $\\epsilon$-greedy (S, Q)\n",
    "  - take action A; observe resultant reward, R and next state S'\n",
    "  - Q(S,A) <- Q(S,A) + $\\alpha$[R + $\\gamma$ $\\max_a$ Q(S', a) - Q(S, A)], direct RL \n",
    "  - Model(S,A) <- R, S', assuming deterministic environment, model update\n",
    "  - Loop repeat n times for planning:\n",
    "    - S <- random previously observed state\n",
    "    - A <- random action previously taken in S\n",
    "    - R, S' <- Model(S, A)\n",
    "    - Q(S,A) <- Q(S,A) + $\\alpha$[R + $\\gamma$ $\\max_a$ Q(S', a) - Q(S, A)]$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
