{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The challenges for directly using SSM in the DRL is:\n",
    "- the unobservable state is not known when using the SSM for planning. For example, how to know the interior/exterior wall temperature for the RC model if it is used for planning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.linen as nn\n",
    "import optax\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from typing import Callable\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(Array(2., dtype=float32), Array(4., dtype=float32, weak_type=True))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test if interpolaiton is differentiable in jax.numpy\n",
    "t = np.arange(10)\n",
    "y = t**2 + 3*t\n",
    "\n",
    "interp = jnp.interp(9.5, t, y) \n",
    "\n",
    "f = lambda x: jnp.interp(x, t, y)\n",
    "grad_fcn = jax.value_and_grad(f)\n",
    "grad_fcn(0.)\n",
    "grad_fcn(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[ 155.16179, -288.31546],\n",
       "       [ 657.3522 , -125.37837],\n",
       "       [ 373.0937 , -112.1631 ]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "class SimpleDense(nn.Module):\n",
    "  features: int\n",
    "  kernel_init: Callable = nn.initializers.lecun_normal()\n",
    "  bias_init: Callable = nn.initializers.zeros_init()\n",
    "\n",
    "  @nn.compact\n",
    "  def __call__(self, inputs):\n",
    "    kernel = self.param('kernel',\n",
    "                        self.kernel_init, # Initialization function\n",
    "                        (inputs.shape[-1], self.features))  # shape info.\n",
    "    y = lax.dot_general(inputs, kernel,\n",
    "                        (((inputs.ndim - 1,), (0,)), ((), ())),) # TODO Why not jnp.dot?\n",
    "    bias = self.param('bias', self.bias_init, (self.features,))\n",
    "    y = y + bias\n",
    "    return y\n",
    "\"\"\"\n",
    "class LSSM(nn.Module):\n",
    "    state_dim: int \n",
    "    action_dim: int\n",
    "    disturbancce_dim: int\n",
    "    output_dim: int\n",
    "    dt: float \n",
    "\n",
    "    initializer: Callable = nn.initializers.lecun_normal()\n",
    "    @nn.compact\n",
    "    def __call__(self, x, u, d):\n",
    "      \"\"\"\n",
    "      x: (b, state_dim)\n",
    "      u: (b, action_dim)\n",
    "      d: (b, disturbance_dim)\n",
    "      \"\"\"\n",
    "      A = self.param('A',\n",
    "                      self.initializer, # initialization\n",
    "                      (self.state_dim, self.state_dim)) # shape\n",
    "      Bu = self.param('Bu',\n",
    "                      self.initializer, # initialization\n",
    "                      (self.state_dim, self.action_dim))\n",
    "      Bd = self.param('Bd',\n",
    "                      self.initializer,\n",
    "                      (self.state_dim, self.disturbancce_dim))\n",
    "\n",
    "      C = self.param('C',\n",
    "                      self.initializer,\n",
    "                      (self.output_dim, self.state_dim))\n",
    "      D = self.param(\"D\",\n",
    "                      self.initializer,\n",
    "                      (self.output_dim, self.action_dim))\n",
    "      xdot = jnp.dot(x, A.T) + jnp.dot(u, Bu.T) + jnp.dot(d, Bd.T)\n",
    "\n",
    "      x_next = xdot * self.dt + x\n",
    "      y_next = jnp.dot(x_next, C.T) + jnp.dot(u, D.T)\n",
    "      \n",
    "      return xdot, x_next, y_next\n",
    "\n",
    "lssm = LSSM(state_dim=3, action_dim=1, disturbancce_dim=4, output_dim=2, dt=900.)\n",
    "\n",
    "key1, key2 = jax.random.split(jax.random.PRNGKey(0), 2)\n",
    "x = jax.random.uniform(key1, (3,3))\n",
    "u = jnp.array([[0.],[0.],[0.]])\n",
    "d = jax.random.uniform(key1, (3,4))\n",
    "params = lssm.init(key2, x, u, d)\n",
    "xdot, x_next, y_next = lssm.apply(params, x, u, d)\n",
    "xdot\n",
    "x_next\n",
    "y_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array([[ 1.0646121e-03, -6.9011992e-05, -7.5943058e-07]], dtype=float32),\n",
       " Array([[19.95815 , 35.93789 , 24.999317]], dtype=float32),\n",
       " Array([[19.95815,  0.     ]], dtype=float32))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# say we have an extact model of the system\n",
    "A = np.array([[-1.97402551e-04,  0.00000000e+00,  1.92610415e-04],\n",
    "              [0.00000000e+00, -3.30784418e-06,  2.00281620e-06],\n",
    "              [1.51360733e-06,  7.56564853e-07, -2.27017218e-06]])\n",
    "Bu = np.array([[9.63095932e-05], [0.], [0.]])\n",
    "Bd = np.array([[4.79213586e-06, 9.63095932e-05, 0.00000000e+00, 0.00000000e+00],\n",
    "               [1.30502798e-06, 0.00000000e+00, 2.00353963e-06, 0.00000000e+00],\n",
    "               [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 7.56838127e-07]])\n",
    "C = np.array([[1., 0., 0.],\n",
    "              [0., 0., 0.]])\n",
    "D = np.array([[0.],\n",
    "              [1.]])\n",
    "\n",
    "ABCD = {'A': A, 'Bu': Bu, 'Bd': Bd, 'C': C, 'D': D}\n",
    "exact_model_params = {\"params\": ABCD}\n",
    "\n",
    "# define the system\n",
    "x0 = np.array([19,36,25])\n",
    "u = 0\n",
    "d = np.array([0,0,0,0])\n",
    "dt = 900\n",
    "\n",
    "# simulate the system\n",
    "lssm = LSSM(state_dim=3, action_dim=1, disturbancce_dim=4, output_dim=2, dt=dt)\n",
    "lssm.apply(exact_model_params, x0, u, d)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork(nn.Module):\n",
    "    @nn.compact\n",
    "    def __call__(self, x):\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(256)(x)\n",
    "        x = nn.relu(x)\n",
    "        x = nn.Dense(2)(x)\n",
    "        return x\n",
    "\n",
    "# we will not learn an environment model here instead we provide an ideal model\n",
    "#class EnvModel(nn.Module):\n",
    "#    @nn.compact\n",
    "#    def __call__(self, x):\n",
    "#        x = nn.Dense(256)(x)\n",
    "#        x = nn.relu(x)\n",
    "#        x = nn.Dense(256)(x)\n",
    "#        x = nn.relu(x)\n",
    "#        x = nn.Dense(256)(x)\n",
    "#        x = nn.relu(x)\n",
    "#        x = nn.Dense(3)(x)  # 3 outputs: 2 states [Tz for next step and power for next step] (although we have simple relationship between power and control action), and reward\n",
    "#        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gymnasium/spaces/box.py:129: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  gym.logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    }
   ],
   "source": [
    "import env\n",
    "# RC model parameters\n",
    "rc_params = [6.9789902e+03, 2.1591113e+04, 1.8807944e+05, 3.4490612e+00, 4.9556872e-01, 9.8289281e-02, 4.6257420e+00]\n",
    "x0 = np.array([20, 35.8, 26.])\n",
    "x_high = np.array([40., 80., 40.])\n",
    "x_low = np.array([10., 10., 10.])\n",
    "n_actions = 101\n",
    "u_high = [0]\n",
    "u_low = [-10.0] # -12\n",
    "\n",
    "# load disturbances\n",
    "file_path = os.path.abspath('')\n",
    "parent_path = os.path.dirname(file_path)\n",
    "data_path = os.path.join(parent_path, 'data/disturbance_1min.csv')\n",
    "data = pd.read_csv(data_path, index_col=[0])\n",
    "# assign time index\n",
    "t_base = 181*24*3600 # 7/1\n",
    "n = len(data)\n",
    "index = range(t_base, t_base + n*60, 60)\n",
    "data.index = index\n",
    "\n",
    "# sample\n",
    "dt = 900\n",
    "data = data.groupby([data.index // dt]).mean()\n",
    "index_dt = range(t_base, t_base + len(data)*dt, dt)\n",
    "data.index = index_dt \n",
    "\n",
    "# get disturbances for lssm\n",
    "t_d = index_dt\n",
    "disturbance_names = ['out_temp', 'qint_lump', 'qwin_lump', 'qradin_lump']\n",
    "disturbance = data[disturbance_names].values\n",
    "\n",
    "# RC Gym envionment\n",
    "ts = 195*24*3600\n",
    "ndays = 7\n",
    "te = ndays*24*3600 + ts\n",
    "weights = [100., 1., 0.] # for energy cost, dT, du\n",
    "\n",
    "env = gym.make(\"R4C3Discrete-v0\",\n",
    "            rc_params = rc_params,\n",
    "            x0 = x0,\n",
    "            x_high = x_high,\n",
    "            x_low = x_low,\n",
    "            n_actions = n_actions,\n",
    "            u_high = u_high,\n",
    "            u_low = u_low,\n",
    "            disturbances = (t_d, disturbance),\n",
    "            ts = ts,\n",
    "            te = te,\n",
    "            dt = dt,\n",
    "            weights = weights).env\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "action_dim = env.action_space.n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env is reset!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:181: UserWarning: \u001b[33mWARN: The obs returned by the `reset()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n",
      "/opt/conda/lib/python3.8/site-packages/gymnasium/utils/passive_env_checker.py:181: UserWarning: \u001b[33mWARN: The obs returned by the `step()` method is not within the observation space.\u001b[0m\n",
      "  logger.warn(f\"{pre} is not within the observation space.\")\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 139\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[39m# DRL state batch to model state batch\u001b[39;00m\n\u001b[1;32m    138\u001b[0m model_state_batch \u001b[39m=\u001b[39m state_batch[:, \u001b[39m1\u001b[39m:\u001b[39m4\u001b[39m] \u001b[39m# [Tz, Twe, Twi]\u001b[39;00m\n\u001b[0;32m--> 139\u001b[0m _, x_predictions, y_predictions \u001b[39m=\u001b[39m env_model\u001b[39m.\u001b[39;49mapply(env_model_params, model_state_batch, control_batch, disturbance_batch)\n\u001b[1;32m    140\u001b[0m \u001b[39m# next_state_batch, reward_batch = env_model.apply(env_model_params, state_action_batch)\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[39m# reconstruct next-state batch\u001b[39;00m\n\u001b[1;32m    142\u001b[0m next_state_batch \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39mconcatenate([next_state_batch[:,\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), x_predictions, next_state_batch[:,\u001b[39m4\u001b[39m:\u001b[39m6\u001b[39m], \u001b[39m-\u001b[39my_predictions[:,\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m,\u001b[39m1\u001b[39m), next_state_batch[:,\u001b[39m7\u001b[39m:]], axis\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:1467\u001b[0m, in \u001b[0;36mModule.apply\u001b[0;34m(self, variables, rngs, method, mutable, capture_intermediates, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1465\u001b[0m   method \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__call__\u001b[39m\n\u001b[1;32m   1466\u001b[0m method \u001b[39m=\u001b[39m _get_unbound_fn(method)\n\u001b[0;32m-> 1467\u001b[0m \u001b[39mreturn\u001b[39;00m apply(\n\u001b[1;32m   1468\u001b[0m     method, \u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1469\u001b[0m     mutable\u001b[39m=\u001b[39;49mmutable,\n\u001b[1;32m   1470\u001b[0m     capture_intermediates\u001b[39m=\u001b[39;49mcapture_intermediates,\n\u001b[1;32m   1471\u001b[0m )(variables, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs, rngs\u001b[39m=\u001b[39;49mrngs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/core/scope.py:933\u001b[0m, in \u001b[0;36mapply.<locals>.wrapper\u001b[0;34m(variables, rngs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    929\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mApplyScopeInvalidVariablesStructureError(variables)\n\u001b[1;32m    931\u001b[0m \u001b[39mwith\u001b[39;00m bind(variables, rngs\u001b[39m=\u001b[39mrngs, mutable\u001b[39m=\u001b[39mmutable,\n\u001b[1;32m    932\u001b[0m           flags\u001b[39m=\u001b[39mflags)\u001b[39m.\u001b[39mtemporary() \u001b[39mas\u001b[39;00m root:\n\u001b[0;32m--> 933\u001b[0m   y \u001b[39m=\u001b[39m fn(root, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    934\u001b[0m \u001b[39mif\u001b[39;00m mutable \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mFalse\u001b[39;00m:\n\u001b[1;32m    935\u001b[0m   \u001b[39mreturn\u001b[39;00m y, root\u001b[39m.\u001b[39mmutable_variables()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:2038\u001b[0m, in \u001b[0;36mapply.<locals>.scope_fn\u001b[0;34m(scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2036\u001b[0m _context\u001b[39m.\u001b[39mcapture_stack\u001b[39m.\u001b[39mappend(capture_intermediates)\n\u001b[1;32m   2037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2038\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(module\u001b[39m.\u001b[39;49mclone(parent\u001b[39m=\u001b[39;49mscope), \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2039\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m   2040\u001b[0m   _context\u001b[39m.\u001b[39mcapture_stack\u001b[39m.\u001b[39mpop()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:424\u001b[0m, in \u001b[0;36mwrap_method_once.<locals>.wrapped_module_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mif\u001b[39;00m args \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(args[\u001b[39m0\u001b[39m], Module):\n\u001b[1;32m    423\u001b[0m   \u001b[39mself\u001b[39m, args \u001b[39m=\u001b[39m args[\u001b[39m0\u001b[39m], args[\u001b[39m1\u001b[39m:]\n\u001b[0;32m--> 424\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_wrapped_method(fun, args, kwargs)\n\u001b[1;32m    425\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m   \u001b[39mreturn\u001b[39;00m fun(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:842\u001b[0m, in \u001b[0;36mModule._call_wrapped_method\u001b[0;34m(self, fun, args, kwargs)\u001b[0m\n\u001b[1;32m    840\u001b[0m \u001b[39mif\u001b[39;00m _use_named_call:\n\u001b[1;32m    841\u001b[0m   \u001b[39mwith\u001b[39;00m jax\u001b[39m.\u001b[39mnamed_scope(_derive_profiling_name(\u001b[39mself\u001b[39m, fun)):\n\u001b[0;32m--> 842\u001b[0m     y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    843\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    844\u001b[0m   y \u001b[39m=\u001b[39m fun(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "Cell \u001b[0;32mIn[3], line 36\u001b[0m, in \u001b[0;36mLSSM.__call__\u001b[0;34m(self, x, u, d)\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[39mx: (b, state_dim)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[39mu: (b, action_dim)\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[39md: (b, disturbance_dim)\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     33\u001b[0m A \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\u001b[39m'\u001b[39m\u001b[39mA\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer, \u001b[39m# initialization\u001b[39;00m\n\u001b[1;32m     35\u001b[0m                 (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim)) \u001b[39m# shape\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m Bu \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam(\u001b[39m'\u001b[39;49m\u001b[39mBu\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m     37\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minitializer, \u001b[39m# initialization\u001b[39;49;00m\n\u001b[1;32m     38\u001b[0m                 (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstate_dim, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maction_dim))\n\u001b[1;32m     39\u001b[0m Bd \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\u001b[39m'\u001b[39m\u001b[39mBd\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     40\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer,\n\u001b[1;32m     41\u001b[0m                 (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisturbancce_dim))\n\u001b[1;32m     43\u001b[0m C \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam(\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     44\u001b[0m                 \u001b[39mself\u001b[39m\u001b[39m.\u001b[39minitializer,\n\u001b[1;32m     45\u001b[0m                 (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moutput_dim, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate_dim))\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/linen/module.py:1219\u001b[0m, in \u001b[0;36mModule.param\u001b[0;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m   1217\u001b[0m   \u001b[39mraise\u001b[39;00m errors\u001b[39m.\u001b[39mNameInUseError(\u001b[39m'\u001b[39m\u001b[39mparam\u001b[39m\u001b[39m'\u001b[39m, name, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m   1218\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mscope \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1219\u001b[0m v \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscope\u001b[39m.\u001b[39;49mparam(name, init_fn, \u001b[39m*\u001b[39;49minit_args, unbox\u001b[39m=\u001b[39;49munbox)\n\u001b[1;32m   1220\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_state\u001b[39m.\u001b[39mchildren[name] \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m   1221\u001b[0m \u001b[39mreturn\u001b[39;00m v\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/core/scope.py:827\u001b[0m, in \u001b[0;36mScope.param\u001b[0;34m(self, name, init_fn, unbox, *init_args)\u001b[0m\n\u001b[1;32m    821\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m, name)\n\u001b[1;32m    822\u001b[0m \u001b[39m# Validate that the shape of the init_fn output is the same as the shape\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m# of the existing parameter. This is to make sure that the hparams set up\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# in a Flax Module match the shapes coming in during apply, and if not,\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[39m# catch it with an error message.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39m# NOTE: We could consider moving this to `self.`\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m abs_value \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39;49meval_shape(\u001b[39mlambda\u001b[39;49;00m rng: init_fn(rng, \u001b[39m*\u001b[39;49minit_args), abs_rng)\n\u001b[1;32m    828\u001b[0m abs_value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(abs_value)\n\u001b[1;32m    829\u001b[0m value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/api.py:3320\u001b[0m, in \u001b[0;36meval_shape\u001b[0;34m(fun, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3318\u001b[0m wrapped_fun, out_tree \u001b[39m=\u001b[39m flatten_fun(lu\u001b[39m.\u001b[39mwrap_init(fun), in_tree)\n\u001b[1;32m   3319\u001b[0m debug_info \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39mdebug_info(fun, in_tree, \u001b[39mTrue\u001b[39;00m, \u001b[39m\"\u001b[39m\u001b[39meval_shape\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 3320\u001b[0m out \u001b[39m=\u001b[39m pe\u001b[39m.\u001b[39;49mabstract_eval_fun(wrapped_fun\u001b[39m.\u001b[39;49mcall_wrapped,\n\u001b[1;32m   3321\u001b[0m                            \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(shaped_abstractify, args_flat),\n\u001b[1;32m   3322\u001b[0m                            debug_info\u001b[39m=\u001b[39;49mdebug_info)\n\u001b[1;32m   3323\u001b[0m out \u001b[39m=\u001b[39m [ShapeDtypeStruct(x\u001b[39m.\u001b[39mshape, x\u001b[39m.\u001b[39mdtype, x\u001b[39m.\u001b[39mnamed_shape) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m out]\n\u001b[1;32m   3324\u001b[0m \u001b[39mreturn\u001b[39;00m tree_unflatten(out_tree(), out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:663\u001b[0m, in \u001b[0;36mabstract_eval_fun\u001b[0;34m(fun, debug_info, *avals, **params)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mabstract_eval_fun\u001b[39m(fun, \u001b[39m*\u001b[39mavals, debug_info\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[0;32m--> 663\u001b[0m   _, avals_out, _ \u001b[39m=\u001b[39m trace_to_jaxpr_dynamic(\n\u001b[1;32m    664\u001b[0m       lu\u001b[39m.\u001b[39;49mwrap_init(fun, params), avals, debug_info)\n\u001b[1;32m    665\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(aval, AbstractValue) \u001b[39mfor\u001b[39;00m aval \u001b[39min\u001b[39;00m avals_out)\n\u001b[1;32m    666\u001b[0m   \u001b[39mreturn\u001b[39;00m avals_out\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/profiler.py:314\u001b[0m, in \u001b[0;36mannotate_function.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m \u001b[39m@wraps\u001b[39m(func)\n\u001b[1;32m    312\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    313\u001b[0m   \u001b[39mwith\u001b[39;00m TraceAnnotation(name, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mdecorator_kwargs):\n\u001b[0;32m--> 314\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    315\u001b[0m   \u001b[39mreturn\u001b[39;00m wrapper\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1989\u001b[0m, in \u001b[0;36mtrace_to_jaxpr_dynamic\u001b[0;34m(fun, in_avals, debug_info, keep_inputs)\u001b[0m\n\u001b[1;32m   1987\u001b[0m \u001b[39mwith\u001b[39;00m core\u001b[39m.\u001b[39mnew_main(DynamicJaxprTrace, dynamic\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39mas\u001b[39;00m main:  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m   1988\u001b[0m   main\u001b[39m.\u001b[39mjaxpr_stack \u001b[39m=\u001b[39m ()  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[0;32m-> 1989\u001b[0m   jaxpr, out_avals, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic(\n\u001b[1;32m   1990\u001b[0m     fun, main, in_avals, keep_inputs\u001b[39m=\u001b[39;49mkeep_inputs, debug_info\u001b[39m=\u001b[39;49mdebug_info)\n\u001b[1;32m   1991\u001b[0m   \u001b[39mdel\u001b[39;00m main, fun\n\u001b[1;32m   1992\u001b[0m \u001b[39mreturn\u001b[39;00m jaxpr, out_avals, consts\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:2006\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_dynamic\u001b[0;34m(fun, main, in_avals, keep_inputs, debug_info)\u001b[0m\n\u001b[1;32m   2004\u001b[0m in_tracers \u001b[39m=\u001b[39m _input_type_to_tracers(trace\u001b[39m.\u001b[39mnew_arg, in_avals)\n\u001b[1;32m   2005\u001b[0m in_tracers_ \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t, keep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(in_tracers, keep_inputs) \u001b[39mif\u001b[39;00m keep]\n\u001b[0;32m-> 2006\u001b[0m ans \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39;49mcall_wrapped(\u001b[39m*\u001b[39;49min_tracers_)\n\u001b[1;32m   2007\u001b[0m out_tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(trace\u001b[39m.\u001b[39mfull_raise, ans)\n\u001b[1;32m   2008\u001b[0m jaxpr, consts \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mto_jaxpr(out_tracers)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/linear_util.py:165\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/linear_util.py:165\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/flax/core/scope.py:827\u001b[0m, in \u001b[0;36mScope.param.<locals>.<lambda>\u001b[0;34m(rng)\u001b[0m\n\u001b[1;32m    821\u001b[0m value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_variable(\u001b[39m'\u001b[39m\u001b[39mparams\u001b[39m\u001b[39m'\u001b[39m, name)\n\u001b[1;32m    822\u001b[0m \u001b[39m# Validate that the shape of the init_fn output is the same as the shape\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[39m# of the existing parameter. This is to make sure that the hparams set up\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[39m# in a Flax Module match the shapes coming in during apply, and if not,\u001b[39;00m\n\u001b[1;32m    825\u001b[0m \u001b[39m# catch it with an error message.\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[39m# NOTE: We could consider moving this to `self.`\u001b[39;00m\n\u001b[0;32m--> 827\u001b[0m abs_value \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39meval_shape(\u001b[39mlambda\u001b[39;00m rng: init_fn(rng, \u001b[39m*\u001b[39;49minit_args), abs_rng)\n\u001b[1;32m    828\u001b[0m abs_value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(abs_value)\n\u001b[1;32m    829\u001b[0m value_flat \u001b[39m=\u001b[39m jax\u001b[39m.\u001b[39mtree_util\u001b[39m.\u001b[39mtree_leaves(value)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/nn/initializers.py:282\u001b[0m, in \u001b[0;36mvariance_scaling.<locals>.init\u001b[0;34m(key, shape, dtype)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[39mif\u001b[39;00m jnp\u001b[39m.\u001b[39missubdtype(dtype, jnp\u001b[39m.\u001b[39mfloating):\n\u001b[1;32m    280\u001b[0m   \u001b[39m# constant is stddev of standard normal truncated to (-2, 2)\u001b[39;00m\n\u001b[1;32m    281\u001b[0m   stddev \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39msqrt(variance) \u001b[39m/\u001b[39m jnp\u001b[39m.\u001b[39marray(\u001b[39m.87962566103423978\u001b[39m, dtype)\n\u001b[0;32m--> 282\u001b[0m   \u001b[39mreturn\u001b[39;00m random\u001b[39m.\u001b[39;49mtruncated_normal(key, \u001b[39m-\u001b[39;49m\u001b[39m2\u001b[39;49m, \u001b[39m2\u001b[39;49m, named_shape, dtype) \u001b[39m*\u001b[39m stddev\n\u001b[1;32m    283\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    284\u001b[0m   \u001b[39m# constant is stddev of complex standard normal truncated to 2\u001b[39;00m\n\u001b[1;32m    285\u001b[0m   stddev \u001b[39m=\u001b[39m jnp\u001b[39m.\u001b[39msqrt(variance) \u001b[39m/\u001b[39m jnp\u001b[39m.\u001b[39marray(\u001b[39m.95311164380491208\u001b[39m, dtype)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/random.py:695\u001b[0m, in \u001b[0;36mtruncated_normal\u001b[0;34m(key, lower, upper, shape, dtype)\u001b[0m\n\u001b[1;32m    693\u001b[0m \u001b[39mif\u001b[39;00m shape \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    694\u001b[0m   shape \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39mas_named_shape(shape)\n\u001b[0;32m--> 695\u001b[0m \u001b[39mreturn\u001b[39;00m _truncated_normal(key, lower, upper, shape, dtype)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/api.py:698\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(execute(\u001b[39m*\u001b[39margs_flat))\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(\n\u001b[0;32m--> 698\u001b[0m       top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params))\n\u001b[1;32m    699\u001b[0m out_pytree_def \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m    700\u001b[0m out \u001b[39m=\u001b[39m tree_unflatten(out_pytree_def, out_flat)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1747\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.process_call\u001b[0;34m(self, call_primitive, f, explicit_tracers, params)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_check_tracer_leaks \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_experimental_subjaxpr_lowering_cache:\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# TODO(lenamartens): Make call_primitive name -> API function name mapping.\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m   \u001b[39m# (currently this will display eg. 'xla_call' instead of `jit`)\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m   dbg \u001b[39m=\u001b[39m debug_info_final(f, call_primitive\u001b[39m.\u001b[39mname)\n\u001b[0;32m-> 1747\u001b[0m   jaxpr, out_type, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic2(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain, debug_info\u001b[39m=\u001b[39;49mdbg)\n\u001b[1;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1749\u001b[0m   jaxpr, out_type, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic2_memoized(\n\u001b[1;32m   1750\u001b[0m       f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain, call_primitive\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:2035\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_dynamic2\u001b[0;34m(fun, main, debug_info)\u001b[0m\n\u001b[1;32m   2033\u001b[0m in_tracers \u001b[39m=\u001b[39m _input_type_to_tracers(trace\u001b[39m.\u001b[39mnew_arg, in_avals)\n\u001b[1;32m   2034\u001b[0m in_tracers_ \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t, keep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(in_tracers, keep_inputs) \u001b[39mif\u001b[39;00m keep]\n\u001b[0;32m-> 2035\u001b[0m ans \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39;49mcall_wrapped(\u001b[39m*\u001b[39;49min_tracers_)\n\u001b[1;32m   2036\u001b[0m out_tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(trace\u001b[39m.\u001b[39mfull_raise, ans)\n\u001b[1;32m   2037\u001b[0m jaxpr, out_type, consts \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mto_jaxpr2(out_tracers)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/linear_util.py:165\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/random.py:715\u001b[0m, in \u001b[0;36m_truncated_normal\u001b[0;34m(key, lower, upper, shape, dtype)\u001b[0m\n\u001b[1;32m    712\u001b[0m out \u001b[39m=\u001b[39m sqrt2 \u001b[39m*\u001b[39m lax\u001b[39m.\u001b[39merf_inv(u)\n\u001b[1;32m    713\u001b[0m \u001b[39m# Clamp the value to the open interval (lower, upper) to make sure that\u001b[39;00m\n\u001b[1;32m    714\u001b[0m \u001b[39m# rounding (or if we chose `a` for `u`) doesn't push us outside of the range.\u001b[39;00m\n\u001b[0;32m--> 715\u001b[0m \u001b[39mreturn\u001b[39;00m jnp\u001b[39m.\u001b[39;49mclip(\n\u001b[1;32m    716\u001b[0m     out,\n\u001b[1;32m    717\u001b[0m     lax\u001b[39m.\u001b[39;49mnextafter(lax\u001b[39m.\u001b[39;49mstop_gradient(lower), np\u001b[39m.\u001b[39;49marray(np\u001b[39m.\u001b[39;49minf, dtype\u001b[39m=\u001b[39;49mdtype)),\n\u001b[1;32m    718\u001b[0m     lax\u001b[39m.\u001b[39;49mnextafter(lax\u001b[39m.\u001b[39;49mstop_gradient(upper), np\u001b[39m.\u001b[39;49marray(\u001b[39m-\u001b[39;49mnp\u001b[39m.\u001b[39;49minf, dtype\u001b[39m=\u001b[39;49mdtype)))\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/api.py:698\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(execute(\u001b[39m*\u001b[39margs_flat))\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(\n\u001b[0;32m--> 698\u001b[0m       top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params))\n\u001b[1;32m    699\u001b[0m out_pytree_def \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m    700\u001b[0m out \u001b[39m=\u001b[39m tree_unflatten(out_pytree_def, out_flat)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1747\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.process_call\u001b[0;34m(self, call_primitive, f, explicit_tracers, params)\u001b[0m\n\u001b[1;32m   1743\u001b[0m \u001b[39mif\u001b[39;00m config\u001b[39m.\u001b[39mjax_check_tracer_leaks \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_experimental_subjaxpr_lowering_cache:\n\u001b[1;32m   1744\u001b[0m   \u001b[39m# TODO(lenamartens): Make call_primitive name -> API function name mapping.\u001b[39;00m\n\u001b[1;32m   1745\u001b[0m   \u001b[39m# (currently this will display eg. 'xla_call' instead of `jit`)\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m   dbg \u001b[39m=\u001b[39m debug_info_final(f, call_primitive\u001b[39m.\u001b[39mname)\n\u001b[0;32m-> 1747\u001b[0m   jaxpr, out_type, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic2(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmain, debug_info\u001b[39m=\u001b[39;49mdbg)\n\u001b[1;32m   1748\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1749\u001b[0m   jaxpr, out_type, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic2_memoized(\n\u001b[1;32m   1750\u001b[0m       f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain, call_primitive\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mval\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:2035\u001b[0m, in \u001b[0;36mtrace_to_subjaxpr_dynamic2\u001b[0;34m(fun, main, debug_info)\u001b[0m\n\u001b[1;32m   2033\u001b[0m in_tracers \u001b[39m=\u001b[39m _input_type_to_tracers(trace\u001b[39m.\u001b[39mnew_arg, in_avals)\n\u001b[1;32m   2034\u001b[0m in_tracers_ \u001b[39m=\u001b[39m [t \u001b[39mfor\u001b[39;00m t, keep \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(in_tracers, keep_inputs) \u001b[39mif\u001b[39;00m keep]\n\u001b[0;32m-> 2035\u001b[0m ans \u001b[39m=\u001b[39m fun\u001b[39m.\u001b[39;49mcall_wrapped(\u001b[39m*\u001b[39;49min_tracers_)\n\u001b[1;32m   2036\u001b[0m out_tracers \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(trace\u001b[39m.\u001b[39mfull_raise, ans)\n\u001b[1;32m   2037\u001b[0m jaxpr, out_type, consts \u001b[39m=\u001b[39m frame\u001b[39m.\u001b[39mto_jaxpr2(out_tracers)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/linear_util.py:165\u001b[0m, in \u001b[0;36mWrappedFun.call_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    162\u001b[0m gen \u001b[39m=\u001b[39m gen_static_args \u001b[39m=\u001b[39m out_store \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    164\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 165\u001b[0m   ans \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m    166\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m    167\u001b[0m   \u001b[39m# Some transformations yield from inside context managers, so we have to\u001b[39;00m\n\u001b[1;32m    168\u001b[0m   \u001b[39m# interrupt them before reraising the exception. Otherwise they will only\u001b[39;00m\n\u001b[1;32m    169\u001b[0m   \u001b[39m# get garbage-collected at some later time, running their cleanup tasks\u001b[39;00m\n\u001b[1;32m    170\u001b[0m   \u001b[39m# only after this exception is handled, which can corrupt the global\u001b[39;00m\n\u001b[1;32m    171\u001b[0m   \u001b[39m# state.\u001b[39;00m\n\u001b[1;32m    172\u001b[0m   \u001b[39mwhile\u001b[39;00m stack:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/numpy/lax_numpy.py:1237\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out)\u001b[0m\n\u001b[1;32m   1235\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mAt most one of a_min and a_max may be None\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1236\u001b[0m \u001b[39mif\u001b[39;00m a_min \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1237\u001b[0m   a \u001b[39m=\u001b[39m maximum(a_min, a)\n\u001b[1;32m   1238\u001b[0m \u001b[39mif\u001b[39;00m a_max \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1239\u001b[0m   a \u001b[39m=\u001b[39m minimum(a_max, a)\n",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/api.py:698\u001b[0m, in \u001b[0;36m_cpp_jit.<locals>.cache_miss\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    695\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(execute(\u001b[39m*\u001b[39margs_flat))\n\u001b[1;32m    696\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    697\u001b[0m   out_flat \u001b[39m=\u001b[39m call_bind_continuation(\n\u001b[0;32m--> 698\u001b[0m       top_trace\u001b[39m.\u001b[39;49mprocess_call(primitive, fun_, tracers, params))\n\u001b[1;32m    699\u001b[0m out_pytree_def \u001b[39m=\u001b[39m out_tree()\n\u001b[1;32m    700\u001b[0m out \u001b[39m=\u001b[39m tree_unflatten(out_pytree_def, out_flat)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1752\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.process_call\u001b[0;34m(self, call_primitive, f, explicit_tracers, params)\u001b[0m\n\u001b[1;32m   1749\u001b[0m     jaxpr, out_type, consts \u001b[39m=\u001b[39m trace_to_subjaxpr_dynamic2_memoized(\n\u001b[1;32m   1750\u001b[0m         f, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmain, call_primitive\u001b[39m.\u001b[39mname)\u001b[39m.\u001b[39mval\n\u001b[1;32m   1751\u001b[0m \u001b[39mif\u001b[39;00m params\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39minline\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m-> 1752\u001b[0m   \u001b[39mreturn\u001b[39;00m core\u001b[39m.\u001b[39;49meval_jaxpr(jaxpr, consts, \u001b[39m*\u001b[39;49min_tracers)\n\u001b[1;32m   1753\u001b[0m source_info \u001b[39m=\u001b[39m source_info_util\u001b[39m.\u001b[39mcurrent()\n\u001b[1;32m   1754\u001b[0m out_tracers \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:409\u001b[0m, in \u001b[0;36meval_jaxpr\u001b[0;34m(jaxpr, consts, *args)\u001b[0m\n\u001b[1;32m    407\u001b[0m name_stack \u001b[39m=\u001b[39m source_info_util\u001b[39m.\u001b[39mcurrent_name_stack() \u001b[39m+\u001b[39m eqn\u001b[39m.\u001b[39msource_info\u001b[39m.\u001b[39mname_stack\n\u001b[1;32m    408\u001b[0m \u001b[39mwith\u001b[39;00m source_info_util\u001b[39m.\u001b[39muser_context(eqn\u001b[39m.\u001b[39msource_info\u001b[39m.\u001b[39mtraceback, name_stack\u001b[39m=\u001b[39mname_stack):\n\u001b[0;32m--> 409\u001b[0m   ans \u001b[39m=\u001b[39m eqn\u001b[39m.\u001b[39;49mprimitive\u001b[39m.\u001b[39;49mbind(\u001b[39m*\u001b[39;49msubfuns, \u001b[39m*\u001b[39;49m\u001b[39mmap\u001b[39;49m(read, eqn\u001b[39m.\u001b[39;49minvars), \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mbind_params)\n\u001b[1;32m    410\u001b[0m \u001b[39mif\u001b[39;00m eqn\u001b[39m.\u001b[39mprimitive\u001b[39m.\u001b[39mmultiple_results:\n\u001b[1;32m    411\u001b[0m   \u001b[39mmap\u001b[39m(write, eqn\u001b[39m.\u001b[39moutvars, ans)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:343\u001b[0m, in \u001b[0;36mPrimitive.bind\u001b[0;34m(self, *args, **params)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams):\n\u001b[1;32m    341\u001b[0m   \u001b[39massert\u001b[39;00m (\u001b[39mnot\u001b[39;00m config\u001b[39m.\u001b[39mjax_enable_checks \u001b[39mor\u001b[39;00m\n\u001b[1;32m    342\u001b[0m           \u001b[39mall\u001b[39m(\u001b[39misinstance\u001b[39m(arg, Tracer) \u001b[39mor\u001b[39;00m valid_jaxtype(arg) \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args)), args\n\u001b[0;32m--> 343\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbind_with_trace(find_top_trace(args), args, params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/core.py:346\u001b[0m, in \u001b[0;36mPrimitive.bind_with_trace\u001b[0;34m(self, trace, args, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbind_with_trace\u001b[39m(\u001b[39mself\u001b[39m, trace, args, params):\n\u001b[0;32m--> 346\u001b[0m   out \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39;49mprocess_primitive(\u001b[39mself\u001b[39;49m, \u001b[39mmap\u001b[39;49m(trace\u001b[39m.\u001b[39;49mfull_raise, args), params)\n\u001b[1;32m    347\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mmap\u001b[39m(full_lower, out) \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmultiple_results \u001b[39melse\u001b[39;00m full_lower(out)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1721\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m   1719\u001b[0m \u001b[39mif\u001b[39;00m primitive \u001b[39min\u001b[39;00m custom_staging_rules:\n\u001b[1;32m   1720\u001b[0m   \u001b[39mreturn\u001b[39;00m custom_staging_rules[primitive](\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39mtracers, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m-> 1721\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdefault_process_primitive(primitive, tracers, params)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/interpreters/partial_eval.py:1730\u001b[0m, in \u001b[0;36mDynamicJaxprTrace.default_process_primitive\u001b[0;34m(self, primitive, tracers, params)\u001b[0m\n\u001b[1;32m   1728\u001b[0m out_tracers \u001b[39m=\u001b[39m [DynamicJaxprTracer(\u001b[39mself\u001b[39m, a, source_info) \u001b[39mfor\u001b[39;00m a \u001b[39min\u001b[39;00m out_avals]\n\u001b[1;32m   1729\u001b[0m invars \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgetvar, tracers)\n\u001b[0;32m-> 1730\u001b[0m outvars \u001b[39m=\u001b[39m \u001b[39mmap\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmakevar, out_tracers)\n\u001b[1;32m   1731\u001b[0m eqn \u001b[39m=\u001b[39m new_jaxpr_eqn(invars, outvars, primitive, params, effects, source_info)\n\u001b[1;32m   1732\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mframe\u001b[39m.\u001b[39madd_eqn(eqn)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/jax/_src/util.py:78\u001b[0m, in \u001b[0;36msafe_map\u001b[0;34m(f, *args)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m args[\u001b[39m1\u001b[39m:]:\n\u001b[1;32m     77\u001b[0m   \u001b[39massert\u001b[39;00m \u001b[39mlen\u001b[39m(arg) \u001b[39m==\u001b[39m n, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mlength mismatch: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(\u001b[39mmap\u001b[39m(\u001b[39mlen\u001b[39m,\u001b[39m \u001b[39margs))\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 78\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39;49m(\u001b[39mmap\u001b[39;49m(f, \u001b[39m*\u001b[39;49margs))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "random.seed(41)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 1e-3\n",
    "gamma = 0.99\n",
    "epsilon = 1.0\n",
    "epsilon_decay = 0.99\n",
    "episodes = 500\n",
    "batch_size = 64\n",
    "planning_steps = 5\n",
    "\n",
    "q_network = QNetwork()\n",
    "env_model = LSSM(state_dim=3, action_dim=1, disturbancce_dim=4, output_dim=2, dt=dt)\n",
    "\n",
    "params = q_network.init(jax.random.PRNGKey(0), jnp.zeros((state_dim,)))\n",
    "env_model_params = exact_model_params\n",
    "\n",
    "optimizer = optax.adam(learning_rate)\n",
    "env_model_optimizer = optax.adam(learning_rate)\n",
    "\n",
    "opt_state = optimizer.init(params)\n",
    "#env_model_opt_state = env_model_optimizer.init(env_model_params)\n",
    "\n",
    "@jax.jit\n",
    "def q_learning_update(params, opt_state, state, action, reward, next_state, done):\n",
    "    def loss_fn(params):\n",
    "        q_values = q_network.apply(params, state)\n",
    "        next_q_values = q_network.apply(params, next_state)\n",
    "        target = reward + gamma * jnp.max(next_q_values, axis=1) * (1 - done)\n",
    "        loss = jnp.mean((q_values[jnp.arange(q_values.shape[0]), action] - target) ** 2)\n",
    "        return loss\n",
    "\n",
    "    loss, grads = jax.value_and_grad(loss_fn)(params)\n",
    "    updates, opt_state = optimizer.update(grads, opt_state)\n",
    "    params = optax.apply_updates(params, updates)\n",
    "    return params, opt_state\n",
    "\n",
    "# env model update \n",
    "#@jax.jit\n",
    "def env_model_update(env_model_params, env_model_opt_state, state, action, next_state, reward):\n",
    "\n",
    "    def env_model_loss_fn(env_model_params):\n",
    "\n",
    "        state_action = jnp.hstack([state, action.reshape(-1,1)])#, axis=1\n",
    "        # predictions of Tz and Power\n",
    "        predictions = env_model.apply(env_model_params, state_action)\n",
    "        # target is next Tz and power\n",
    "        Tz_target = next_state[:,1]\n",
    "        power_target = next_state[:,4]\n",
    "        \n",
    "        target = jnp.stack([Tz_target, power_target, reward], axis=1)\n",
    "        print(target.shape, predictions.shape)\n",
    "        print(\"in model update\")\n",
    "        env_model_loss = jnp.mean(jnp.square(predictions - target))\n",
    "        return env_model_loss\n",
    "\n",
    "    env_model_loss, env_model_grads = jax.value_and_grad(env_model_loss_fn)(env_model_params)\n",
    "    env_model_updates, env_model_opt_state = env_model_optimizer.update(env_model_grads, env_model_opt_state)\n",
    "    env_model_params = optax.apply_updates(env_model_params, env_model_updates)\n",
    "    return env_model_params, env_model_opt_state\n",
    "\n",
    "\n",
    "def get_objective_batch(t, Tz, P, env):\n",
    "    t = t.astype(jnp.int32)\n",
    "    h = (t%86400/3600).astype(jnp.int32)\n",
    "\n",
    "    price = env.energy_price\n",
    "    Tz_ub = env.Tz_high\n",
    "    Tz_lb = env.Tz_low \n",
    "\n",
    "    price_batch = jnp.array([price[i] for i in h])\n",
    "    cost_batch = price_batch*P*env.dt/3600.\n",
    "    Tz_high_batch = jnp.array([Tz_ub[i] for i in h])\n",
    "    Tz_low_batch = jnp.array([Tz_lb[i] for i in h])\n",
    "\n",
    "    dTz = jnp.fmax(Tz - Tz_high_batch, Tz_low_batch - Tz)\n",
    "    dTz = jnp.fmax(dTz, 0)\n",
    "\n",
    "    du = 0\n",
    "\n",
    "    return -(env.weights[0]*cost_batch + env.weights[1]*dTz + env.weights[2]*du)\n",
    "\n",
    "buffer_size = 200000\n",
    "memory = deque(maxlen=buffer_size)\n",
    "reward_history = []\n",
    "reward_threshold=175 # env.spec.reward_threshold\n",
    "solved_window = 100\n",
    "\n",
    "for episode in range(episodes):\n",
    "    state, _ = env.reset(seed=1)\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "    step_in_episode = 0\n",
    "\n",
    "    while not done:\n",
    "        if random.random() < epsilon:\n",
    "            action = env.action_space.sample()\n",
    "        else:\n",
    "            q_values = q_network.apply(params, jnp.expand_dims(jnp.array(state), axis=0))\n",
    "            action = jnp.argmax(q_values).item()\n",
    "\n",
    "        next_state, reward, done, _, _ = env.step(action)\n",
    "\n",
    "        memory.append((env.t, state, action, reward, next_state, done))\n",
    "        state = next_state\n",
    "        total_reward += reward\n",
    "        step_in_episode += 1\n",
    "\n",
    "        if len(memory) >= batch_size:\n",
    "            batch = random.sample(memory, batch_size)\n",
    "            #t_batch = jnp.array([t for (t, _, _, _, _, _) in batch])\n",
    "            state_batch = jnp.array([s for (_, s, _, _, _, _) in batch])\n",
    "            action_batch = jnp.array([a for (_, _, a, _, _, _) in batch])\n",
    "            reward_batch = jnp.array([r for (_, _, _, r, _, _) in batch])\n",
    "            next_state_batch = jnp.array([ns for (_, _, _, _, ns, _) in batch])\n",
    "            done_batch = jnp.array([d for (_, _, _, _, _, d) in batch], dtype=jnp.float32)\n",
    "\n",
    "            params, opt_state = q_learning_update(params, opt_state, state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
    "            # model learning: since we're using perfect env model, this is not needed.\n",
    "            #env_model_params, env_model_opt_state = env_model_update(env_model_params, env_model_opt_state, state_batch, action_batch, next_state_batch, reward_batch)\n",
    "\n",
    "            for _ in range(planning_steps):\n",
    "                planning_batch = random.sample(memory, batch_size)\n",
    "                t_batch = jnp.array([t for (t, _, _, _, _, _) in planning_batch])\n",
    "                state_batch = jnp.array([s for (_, s, _, _, _, _) in planning_batch]) # random sample for states\n",
    "                # random actions for exploration\n",
    "                # choose from previously observed actions\n",
    "                # action_batch = jnp.array([a for (_, a, _, _, _) in batch]) # random sample for actions\n",
    "                # choose from action space\n",
    "                action_batch = jnp.array([random.choice(range(action_dim)) for _ in range(batch_size)])\n",
    "                # disctete action to control inputs\n",
    "                control_batch = jnp.array([action/(env.n_actions-1)*(env.u_high - env.u_low) + env.u_low for action in action_batch])\n",
    "                \n",
    "                #state_action_batch = jnp.concatenate([state_batch, action_batch[:, np.newaxis]], axis=1)\n",
    "                disturbance_batch = env.dist_fcn.evaluate(t_batch)\n",
    "                \n",
    "                # DRL state batch to model state batch\n",
    "                model_state_batch = state_batch[:, 1:4] # [Tz, Twe, Twi]\n",
    "                _, x_predictions, y_predictions = env_model.apply(env_model_params, model_state_batch, control_batch, disturbance_batch)\n",
    "                # next_state_batch, reward_batch = env_model.apply(env_model_params, state_action_batch)\n",
    "                # reconstruct next-state batch\n",
    "                next_state_batch = jnp.concatenate([next_state_batch[:,0].reshape(-1,1), x_predictions, next_state_batch[:,4:6], -y_predictions[:,1].reshape(-1,1), next_state_batch[:,7:]], axis=1)\n",
    "                \n",
    "                # reconstruct reward batch: we avoid du in objective, otherwise we have to save previous action in memeory\n",
    "                Tz = x_predictions[:,0]\n",
    "                P = -y_predictions[:,1]\n",
    "                \n",
    "                reward_batch = get_objective_batch(t_batch, Tz, P, env)\n",
    "                \n",
    "                done_batch = jnp.full(reward_batch.shape, False, dtype=jnp.float32)\n",
    "                #done_batch = (jnp.abs(jnp.sum(next_state_batch - state_batch, axis=1)) > 0.5).astype(jnp.float32)\n",
    "\n",
    "                params, opt_state = q_learning_update(params, opt_state, state_batch, action_batch, reward_batch, next_state_batch, done_batch)\n",
    "        \n",
    "        # episode stopping: NOT IMPLEMENTED.\n",
    "\n",
    "    epsilon = max(epsilon * epsilon_decay, 0.01)\n",
    "    print(f\"Episode {episode + 1}, Total Reward: {total_reward}\")\n",
    "\n",
    "    # outputs\n",
    "    reward_history.append(total_reward)\n",
    "\n",
    "    # stop training if average reward reaches requirement\n",
    "    # Calculate the average reward over the last 'solved_window' episodes\n",
    "    if episode >= solved_window:\n",
    "        avg_reward = np.mean(reward_history[-solved_window:])\n",
    "        print(f'Episode: {episode}, Average Reward: {avg_reward}')\n",
    "\n",
    "        if avg_reward >= reward_threshold:\n",
    "            print(f\"R4C3Discrete-v0 solved in {episode} episodes!\")\n",
    "            break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Plot the historical rewards\n",
    "plt.plot(reward_history)\n",
    "plt.xlabel(\"Episode\")\n",
    "plt.ylabel(\"Total Reward\")\n",
    "plt.title(\"Historical Rewards for CartPole-v1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training \n",
    "def plot_moving_average_reward(episode_rewards, window_size=100):\n",
    "    cumsum_rewards = np.cumsum(episode_rewards)\n",
    "    moving_avg_rewards = (cumsum_rewards[window_size:] - cumsum_rewards[:-window_size]) / window_size\n",
    "\n",
    "    plt.plot(moving_avg_rewards)\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Moving Average Reward')\n",
    "    plt.title('Moving Average Reward over Episodes')\n",
    "    plt.show()\n",
    "\n",
    "plot_moving_average_reward(reward_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need a virtual display for rendering in docker\n",
    "from pyvirtualdisplay import Display\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start()\n",
    "from IPython import display as ipythondisplay\n",
    "\n",
    "# Test the trained agent\n",
    "\n",
    "print(\"\\nTesting the trained agent...\")\n",
    "env = gym.make(\"CartPole-v1\",render_mode='rgb_array').env\n",
    "state, _ = env.reset()\n",
    "state = jnp.array(state, dtype=jnp.float32)\n",
    "\n",
    "total_reward = 0\n",
    "done = False\n",
    "pre_screen = env.render()\n",
    "step_in_episode = 0\n",
    "\n",
    "while not done:\n",
    "    q_values = q_network.apply(params, jnp.expand_dims(jnp.array(state), axis=0))\n",
    "    action = jnp.argmax(q_values).item()\n",
    "    #action = agent.act(state)\n",
    "    next_state, reward, done, _, _ = env.step(action)\n",
    "    next_state = jnp.array(next_state, dtype=jnp.float32)\n",
    "    screen = env.render()\n",
    "    state = next_state\n",
    "    total_reward += reward\n",
    "    step_in_episode += 1\n",
    "\n",
    "    plt.imshow(screen)\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    ipythondisplay.display(plt.gcf())\n",
    "\n",
    "    # check if the max_episode_steps are met. if so, terminate this episode\n",
    "    if step_in_episode >= max_episode_steps:\n",
    "        print(f\"Agent reached max_episode_steps in test.\")\n",
    "        break\n",
    "\n",
    "    ipythondisplay.clear_output(wait=True)\n",
    "    \n",
    "print(f\"Total Reward: {total_reward}\")\n",
    "\n",
    "env.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(pre_screen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
