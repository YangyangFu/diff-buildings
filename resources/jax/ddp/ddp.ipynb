{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Differentiable Dynamic Programming\n",
    "This section is to solve the Bellman equation using differentiable dynamic programming (DDP).\n",
    "Refer to [Differentiable Optimal Control via Differential Dynamic Programming](https://arxiv.org/pdf/2209.01117.pdf) and a Python implementation [here](https://github.com/neka-nat/ddp-gym/blob/master/ddp_gym.py).\n",
    "\n",
    "DDP is designed for solving nonlinear dynamic system optimal control, which performs a quadratic approximation of the cost based on Taylor Series.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## System Dynamics\n",
    "\n",
    "\\begin{align}\n",
    "x_{t+1} &= f(x_t, u_t) \\\\\n",
    "x_0 &= x(0)\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cost Function\n",
    "\n",
    "The `cost-to-go` function at time `t` is shown as follows:\n",
    "\n",
    "\\begin{align}\n",
    "    J(x_t, U_t) &= \\sum_{k=t}^{N-1}\\ell(x_k, u_k) + \\ell_f(x_N) \\\\\n",
    "    U_t &= \\{u_t, ..., u_{N-1}\\}\n",
    "\\end{align}\n",
    "\n",
    "Minimum `cost-to-go` or `value function` at time `t` is then:\n",
    "\n",
    "\\begin{align}\n",
    "    V_t(x_t) &= \\min_{U_t} J_t(x_t, U_t) \\\\\n",
    "            &= \\min_{u_t, ..., u_{N-1}} \\sum_{k=t}^{N-1} \\ell(x_k, u_k) + \\ell_f(x_{N}) \\\\\n",
    "            &= \\min_{u_t} [\\ell(x_t, u_t) + V_{t+1}(x_{t+1})] \\\\\n",
    "            &= \\min_{u_t} [\\ell(x_t, u_t) + V_{t+1}(f(x_t, u_t)] \\\\\n",
    "            &= \\min_{u_t} Q_t(x_t, u_t)\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Second-order Approximation of Q-function\n",
    "For linear system and quadratic cost function $\\ell$, $Q$ is quadratic.\n",
    "But when the system is nonlinear, $Q$ is no longer quadratic.\n",
    "DDP is to approximate the action-value function $Q$ in a quadratic format, which can be done based on Taylor Series.\n",
    "\n",
    "DDP iterates between\n",
    "- (i) minimizing the quadratic approximation of the Q-function in a `backward pass`, and \n",
    "- (ii) integrating the system dynamics in a `forward pass`\n",
    "\n",
    "Given a sequence of nominal control trajectory $U_t^r = \\{u_t^r, ..., u_{N-1}^r\\}$, and a sequence of nominal state trajectory $X_t^r = \\{x_t^r, ..., x_N^r\\}$, we can approximate $Q_t(u_t, x_t)$ around the given nominal conditions based on Taylor series. \n",
    "Let's drop the subscript `t` for brivity:\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat Q(x_t,u_t) = Q(x_t^r, u_t^r) + Q_x \\Delta x_t + Q_u \\Delta u_t + \\frac{1}{2}\\Delta x_t^T Q_{xx} \\Delta x_t + \\frac{1}{2}\\Delta u_t^T Q_{uu} \\Delta u_t + \\Delta u_t^TQ_{ux} \\Delta x_t \n",
    "\\end{equation}\n",
    "\n",
    "where $\\Delta u_t = u_t - u_t^r$, and $\\Delta x_t = x_t - x_t^r$.\n",
    "\n",
    "The first-order and second-order partial derivatives of $Q$ can be calculated as:\n",
    "\n",
    "\\begin{align}\n",
    "Q_x &= \\ell_x + f_x^TV_{x,t+1} \\\\\n",
    "Q_u &= \\ell_u + f_u^TV_{x,t+1} \\\\\n",
    "Q_{xx} &= \\ell_{xx} + f_x^TV_{xx,t+1} f_x + V_{x,t+1} f_{xx} \\\\\n",
    "Q_{uu} &= \\ell_{uu} + f_u^TV_{uu,t+1} f_u + V_{x,t+1} f_{uu} \\\\\n",
    "Q_{ux} &= \\ell_{ux} + f_u^TV_{ux,t+1} f_x + V_{x,t+1} f_{ux}\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "Then optimal control problem then becomes\n",
    "\\begin{equation}\n",
    "    \\Delta u^* = \\argmin_{\\Delta u} \\hat Q(x, u) = -Q_{uu}^{-1}Q_u - Q_{uu}^{-1}Q_{ux}\\Delta x = -k - K\\Delta x\n",
    "\\end{equation}\n",
    "\n",
    "Use this optimal $\\Delta u$ and known nominal control inputs $u^r$, we can then calculate the optimal cost-to-go $V$ in a backward pass from $t = N$ to $t = 1$:\n",
    "\n",
    "\\begin{align}\n",
    "u_t^* &= u_t^r + \\Delta u_t^* \\\\\n",
    "V(x_t) &= Q(x_t, u_t^*) = Q(x_t^r, u_t^r) - Q_uQ_{uu}^{-1}Q_u \\\\\n",
    "V_x &= Q_x - Q_{ux}Q_{uu}^{-1}Q_u \\\\ \n",
    "V_{xx} &= Q_{xx} - Q_{ux}Q_{uu}^{-1}Q_{ux}\n",
    "\\end{align}\n",
    "\n",
    "Then we can perform a forward pass from $t= 0$ to $t=N-1$ to calculate the new nominal state trajectories using the optimal control inputs:\n",
    "\n",
    "\\begin{align}\n",
    "\\hat x_0 &= x(0) \\\\\n",
    "\\Delta \\hat u_t &= \\hat u_t - u_t^r = -k_t - K_t(\\hat x_t - x_t^r) \\\\\n",
    "\\hat x_{t+1} &= f(\\hat x_t, \\hat u_t)\n",
    "\\end{align}\n",
    "\n",
    "The backward pass and forward pass are iterated until convergence.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Procedure**\n",
    "- generate a nominal trajectory for control inputs $\\{u_0^r, u_1^r, ..., u_{N-1}^r\\}$\n",
    "- forward pass to calculate the nominal trajectory for system states $\\{x_0^r, x_1^r, ..., x_N^r\\}$\n",
    "- set $V_N(x_N) = \\ell_f(x_N)$, and calculate $V_x$ and $V_{xx}$ at $t = N$\n",
    "- backward pass: for t = N, ..., 1:\n",
    "  - calculate $Q_x$, $Q_u$, $Q_{xx}$, $Q_{uu}$ and $Q_{ux}$ at $t-1$\n",
    "  - calculate $k_{t-1}, K_{t-1}$\n",
    "- initiate $\\hat x_0 = x(0)$\n",
    "- forward pass: for t = 0, ..., N-1:\n",
    "  - calculate $\\Delta x_t = \\hat x_t - x_t^r$\n",
    "  - calculate control input changes $\\Delta \\hat u_t$ based on $k_t$, $K_t$ and $\\Delta x_t$\n",
    "  - calculate improved control input $\\hat u_t = u_t^r + \\Delta \\hat u_t$\n",
    "  - calculate improved state trajectory $\\hat x_{t+1}$\n",
    "- repeat until convergence\n",
    "  - $V(x_0)$ is minimized and converged\n",
    "  - max iteration is reached \n",
    "  - etc ... \n",
    "  \n",
    "  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deveopment Ideas\n",
    "- DDP class\n",
    "- interact with openGym environment"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example\n",
    "\n",
    "### Problem 1\n",
    "\n",
    "Solve a pendulum problem as described https://gymnasium.farama.org/environments/classic_control/pendulum/. This is a nonlinear system for control.\n",
    "\n",
    "\n",
    "\\begin{align}\n",
    "\\ddot \\theta = \\frac{3g}{2l}\\sin(\\theta) + \\frac{3}{ml^2}\\tau\n",
    "\\end{align}\n",
    "\n",
    "The state-space model can be expressed as:\n",
    "\n",
    "\\begin{align}\n",
    "    \\begin{bmatrix}\n",
    "    \\dot \\theta \\\\\n",
    "    \\ddot \\theta\n",
    "    \\end{bmatrix} \n",
    "    = \n",
    "    \\begin{bmatrix}\n",
    "    \\dot \\theta \\\\\n",
    "    \\frac{3g}{2l}\\sin(\\theta)\n",
    "    \\end{bmatrix}\n",
    "    +\n",
    "    \\begin{bmatrix}\n",
    "    0  \\\\\n",
    "    \\frac{3}{ml^2}\n",
    "    \\end{bmatrix}\n",
    "    \\tau\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The discrete-time dynamics using explicit Euler method is obtained as:\n",
    "\n",
    "\\begin{align}\n",
    "    \\dot \\theta_{t+1} &= \\dot \\theta_t + \\frac{3g}{2l}\\sin(\\theta_t) \\Delta t + \\frac{3}{ml^2} \\tau_t\\Delta t \\\\\n",
    "    \\theta_{t+1} &= \\theta_t + \\dot \\theta_{t+1} \\Delta t\n",
    "\\end{align}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's define cost functions:\n",
    "\n",
    "\\begin{align}\n",
    "    J((\\theta_t, \\dot \\theta_t), \\tau_t) = \\sum_{k=t}^{N-1} (\\theta_t^2 + 0.1*\\dot \\theta_t^2 + 0.001* \\tau_t^2)\n",
    "\\end{align}\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 1\n",
    "g = 9.8\n",
    "l = 1\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2:\n",
    "\n",
    "Continuous Car Pole -> find the optimal force\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W_grad [-0.16965583 -0.8774644  -1.4901346 ]\n",
      "W_grad [-0.16965589 -0.8774646  -1.4901345 ]\n",
      "b_grad -0.29227245\n",
      "W_grad [-0.16965583 -0.8774644  -1.4901346 ]\n",
      "b_grad -0.29227245\n",
      "W_hessian [[ 0.13086347  0.02744001 -0.10441232]\n",
      " [ 0.02744001  0.21013734  0.06696167]\n",
      " [-0.10441236  0.06696158  0.46901628]]\n",
      "b_hessian 0.3969572\n",
      "W_hessian [[ 0.13086347  0.02744001 -0.10441232]\n",
      " [ 0.02744001  0.21013734  0.06696167]\n",
      " [-0.10441236  0.06696158  0.46901628]]\n",
      "l_Wb [ 0.22326396  0.08888979 -0.20664802]\n",
      "l_bW [ 0.2232639   0.08888967 -0.20664799]\n",
      "b_hessian 0.3969572\n"
     ]
    }
   ],
   "source": [
    "import jax \n",
    "from jax import grad, jacrev, jacfwd, hessian \n",
    "from jax import numpy as jnp\n",
    "import numpy as np\n",
    "from jax import random\n",
    "\n",
    "key = random.PRNGKey(0)\n",
    "\n",
    "# scalor function\n",
    "def sigmoid(x):\n",
    "    return 0.5 * (jnp.tanh(x / 2) + 1)\n",
    "\n",
    "# Outputs probability of a label being true.\n",
    "def predict(W, b, inputs):\n",
    "    return sigmoid(jnp.dot(inputs, W) + b)\n",
    "\n",
    "# Build a toy dataset.\n",
    "inputs = jnp.array([[0.52, 1.12,  0.77],\n",
    "                   [0.88, -1.08, 0.15],\n",
    "                   [0.52, 0.06, -1.30],\n",
    "                   [0.74, -2.49, 1.39]])\n",
    "targets = jnp.array([True, True, False, True])\n",
    "\n",
    "# Training loss is the negative log-likelihood of the training examples.\n",
    "def loss(W, b):\n",
    "    preds = predict(W, b, inputs)\n",
    "    label_probs = preds * targets + (1 - preds) * (1 - targets)\n",
    "    return -jnp.sum(jnp.log(label_probs))\n",
    "\n",
    "# Initialize random model coefficients\n",
    "key, W_key, b_key = random.split(key, 3)\n",
    "W = random.normal(W_key, (3,))\n",
    "b = random.normal(b_key, ())\n",
    "\n",
    "# Differentiate `loss` with respect to the first positional argument:\n",
    "W_grad = grad(loss, 0)(W, b)\n",
    "print('W_grad', W_grad)\n",
    "\n",
    "# Since argnums=0 is the default, this does the same thing:\n",
    "W_grad = jacfwd(loss)(W, b)\n",
    "print('W_grad', W_grad)\n",
    "\n",
    "# But we can choose different values too, and drop the keyword:\n",
    "b_grad = grad(loss, 1)(W, b)\n",
    "print('b_grad', b_grad)\n",
    "\n",
    "# Including tuple values\n",
    "W_grad, b_grad = grad(loss, (0, 1))(W, b)\n",
    "print('W_grad', W_grad)\n",
    "print('b_grad', b_grad)\n",
    "\n",
    "# hessian\n",
    "l_WW = hessian(loss, 0)(W,b)\n",
    "print('W_hessian', l_WW)\n",
    "\n",
    "l_bb = hessian(loss, 1)(W,b)\n",
    "print('b_hessian', l_bb)\n",
    "\n",
    "(l_WW, l_Wb), (l_bW, l_bb) = hessian(loss, (0, 1))(W,b)\n",
    "print('W_hessian', l_WW)\n",
    "print('l_Wb', l_Wb)\n",
    "print('l_bW', l_bW)\n",
    "print('b_hessian', l_bb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "#import env\n",
    "from jax import grad\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import copy\n",
    "import math\n",
    "\n",
    "class DDP:\n",
    "    def __init__(self, next_state, running_cost, final_cost,\n",
    "                 umax, state_dim, pred_time=50):\n",
    "        self.pred_time = pred_time\n",
    "        self.umax = umax\n",
    "        self.v = [0.0 for _ in range(pred_time + 1)]\n",
    "        self.v_x = [jnp.zeros(state_dim) for _ in range(pred_time + 1)]\n",
    "        self.v_xx = [jnp.zeros((state_dim, state_dim))\n",
    "                     for _ in range(pred_time + 1)]\n",
    "        self.f = next_state\n",
    "        self.lf = final_cost\n",
    "        self.l = running_cost\n",
    "        self.lf_x = grad(self.lf)\n",
    "        self.lf_xx = grad(self.lf_x)\n",
    "        self.l_x = grad(self.l, 0)\n",
    "        self.l_u = grad(self.l, 1)\n",
    "        self.l_xx = grad(self.l_x, 0)\n",
    "        self.l_uu = grad(self.l_u, 1)\n",
    "        self.l_ux = grad(self.l_u, 0)\n",
    "        self.f_x = grad(self.f, 0)\n",
    "        self.f_u = grad(self.f, 1)\n",
    "        self.f_xx = grad(self.f_x, 0)\n",
    "        self.f_uu = grad(self.f_u, 1)\n",
    "        self.f_ux = grad(self.f_u, 0)\n",
    "\n",
    "    def backward(self, x_seq, u_seq):\n",
    "        self.v[-1] = self.lf(x_seq[-1])\n",
    "        self.v_x[-1] = self.lf_x(x_seq[-1])\n",
    "        self.v_xx[-1] = self.lf_xx(x_seq[-1])\n",
    "        k_seq = []\n",
    "        kk_seq = []\n",
    "        for t in range(self.pred_time - 1, -1, -1):\n",
    "            f_x_t = self.f_x(x_seq[t], u_seq[t])\n",
    "            f_u_t = self.f_u(x_seq[t], u_seq[t])\n",
    "            q_x = self.l_x(x_seq[t], u_seq[t]) + \\\n",
    "                jnp.matmul(f_x_t.T, self.v_x[t + 1])\n",
    "            q_u = self.l_u(x_seq[t], u_seq[t]) + \\\n",
    "                jnp.matmul(f_u_t.T, self.v_x[t + 1])\n",
    "            q_xx = self.l_xx(x_seq[t], u_seq[t]) + \\\n",
    "                jnp.matmul(jnp.matmul(f_x_t.T, self.v_xx[t + 1]), f_x_t) + \\\n",
    "                jnp.dot(self.v_x[t + 1],\n",
    "                       jnp.squeeze(self.f_xx(x_seq[t], u_seq[t])))\n",
    "            tmp = jnp.matmul(f_u_t.T, self.v_xx[t + 1])\n",
    "            q_uu = self.l_uu(x_seq[t], u_seq[t]) + jnp.matmul(tmp, f_u_t) + \\\n",
    "                jnp.dot(self.v_x[t + 1],\n",
    "                       np.squeeze(self.f_uu(x_seq[t], u_seq[t])))\n",
    "            q_ux = self.l_ux(x_seq[t], u_seq[t]) + jnp.matmul(tmp, f_x_t) + \\\n",
    "                jnp.dot(self.v_x[t + 1],\n",
    "                       jnp.squeeze(self.f_ux(x_seq[t], u_seq[t])))\n",
    "            inv_q_uu = jnp.linalg.inv(q_uu)\n",
    "            k = -jnp.matmul(inv_q_uu, q_u)\n",
    "            kk = -jnp.matmul(inv_q_uu, q_ux)\n",
    "            dv = 0.5 * jnp.matmul(q_u, k)\n",
    "            self.v[t] += dv\n",
    "            self.v_x[t] = q_x - jnp.matmul(jnp.matmul(q_u, inv_q_uu), q_ux)\n",
    "            self.v_xx[t] = q_xx + jnp.matmul(q_ux.T, kk)\n",
    "            k_seq.append(k)\n",
    "            kk_seq.append(kk)\n",
    "        k_seq.reverse()\n",
    "        kk_seq.reverse()\n",
    "        return k_seq, kk_seq\n",
    "\n",
    "    def forward(self, x_seq, u_seq, k_seq, kk_seq):\n",
    "        x_seq_hat = jnp.array(x_seq)\n",
    "        u_seq_hat = jnp.array(u_seq)\n",
    "        for t in range(len(u_seq)):\n",
    "            control = k_seq[t] + \\\n",
    "                jnp.matmul(kk_seq[t], (x_seq_hat[t] - x_seq[t]))\n",
    "            u_seq_hat[t] = jnp.clip(u_seq[t] + control, -self.umax, self.umax)\n",
    "            x_seq_hat[t + 1] = self.f(x_seq_hat[t], u_seq_hat[t])\n",
    "        return x_seq_hat, u_seq_hat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameNotFound",
     "evalue": "Environment CartPoleContinuous doesn't exist. Did you mean: `MountainCarContinuous`?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameNotFound\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 31\u001b[0m\n\u001b[1;32m     27\u001b[0m         theta \u001b[39m=\u001b[39m theta \u001b[39m+\u001b[39m env\u001b[39m.\u001b[39mtau \u001b[39m*\u001b[39m theta_dot\n\u001b[1;32m     29\u001b[0m     \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39marray([x, x_dot, theta, theta_dot])\n\u001b[0;32m---> 31\u001b[0m env \u001b[39m=\u001b[39m gym\u001b[39m.\u001b[39;49mmake(\u001b[39m'\u001b[39;49m\u001b[39mCartPoleContinuous-v0\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39menv\n\u001b[1;32m     33\u001b[0m obs \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mreset()\n\u001b[1;32m     34\u001b[0m ddp \u001b[39m=\u001b[39m DDP(\u001b[39mlambda\u001b[39;00m x, u: dynamics(env, x, u),  \u001b[39m# x(i+1) = f(x(i), u)\u001b[39;00m\n\u001b[1;32m     35\u001b[0m           \u001b[39mlambda\u001b[39;00m x, u: \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m np\u001b[39m.\u001b[39msum(np\u001b[39m.\u001b[39msquare(u)),  \u001b[39m# l(x, u)\u001b[39;00m\n\u001b[1;32m     36\u001b[0m           \u001b[39mlambda\u001b[39;00m x: \u001b[39m0.5\u001b[39m \u001b[39m*\u001b[39m \\\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     39\u001b[0m           env\u001b[39m.\u001b[39mforce_max,\n\u001b[1;32m     40\u001b[0m           env\u001b[39m.\u001b[39mobservation_space\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gymnasium/envs/registration.py:592\u001b[0m, in \u001b[0;36mmake\u001b[0;34m(id, max_episode_steps, autoreset, apply_api_compatibility, disable_env_checker, **kwargs)\u001b[0m\n\u001b[1;32m    586\u001b[0m         logger\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    587\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUsing the latest versioned environment `\u001b[39m\u001b[39m{\u001b[39;00mnew_env_id\u001b[39m}\u001b[39;00m\u001b[39m` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    588\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39minstead of the unversioned environment `\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    589\u001b[0m         )\n\u001b[1;32m    591\u001b[0m     \u001b[39mif\u001b[39;00m spec_ \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m         _check_version_exists(ns, name, version)\n\u001b[1;32m    593\u001b[0m         \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mNo registered env with id: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    595\u001b[0m _kwargs \u001b[39m=\u001b[39m spec_\u001b[39m.\u001b[39mkwargs\u001b[39m.\u001b[39mcopy()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gymnasium/envs/registration.py:218\u001b[0m, in \u001b[0;36m_check_version_exists\u001b[0;34m(ns, name, version)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mif\u001b[39;00m get_env_id(ns, name, version) \u001b[39min\u001b[39;00m registry:\n\u001b[1;32m    216\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[0;32m--> 218\u001b[0m _check_name_exists(ns, name)\n\u001b[1;32m    219\u001b[0m \u001b[39mif\u001b[39;00m version \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    220\u001b[0m     \u001b[39mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.8/site-packages/gymnasium/envs/registration.py:195\u001b[0m, in \u001b[0;36m_check_name_exists\u001b[0;34m(ns, name)\u001b[0m\n\u001b[1;32m    192\u001b[0m namespace_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m in namespace \u001b[39m\u001b[39m{\u001b[39;00mns\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m ns \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    193\u001b[0m suggestion_msg \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDid you mean: `\u001b[39m\u001b[39m{\u001b[39;00msuggestion[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m`?\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m suggestion \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 195\u001b[0m \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mNameNotFound(\n\u001b[1;32m    196\u001b[0m     \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEnvironment \u001b[39m\u001b[39m{\u001b[39;00mname\u001b[39m}\u001b[39;00m\u001b[39m doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt exist\u001b[39m\u001b[39m{\u001b[39;00mnamespace_msg\u001b[39m}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m{\u001b[39;00msuggestion_msg\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    197\u001b[0m )\n",
      "\u001b[0;31mNameNotFound\u001b[0m: Environment CartPoleContinuous doesn't exist. Did you mean: `MountainCarContinuous`?"
     ]
    }
   ],
   "source": [
    "def dynamics(env, state, action):\n",
    "    x, x_dot, theta, theta_dot = state\n",
    "    force = action[0]\n",
    "    costheta = math.cos(theta)\n",
    "    sintheta = math.sin(theta)\n",
    "\n",
    "    # For the interested reader:\n",
    "    # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "    temp = (\n",
    "        force + env.polemass_length * theta_dot**2 * sintheta\n",
    "    ) / env.total_mass\n",
    "    thetaacc = (env.gravity * sintheta - costheta * temp) / (\n",
    "        env.length * (4.0 / 3.0 - env.masspole *\n",
    "                    costheta**2 / env.total_mass)\n",
    "    )\n",
    "    xacc = temp - env.polemass_length * thetaacc * costheta / env.total_mass\n",
    "\n",
    "    if env.kinematics_integrator == \"euler\":\n",
    "        x = x + env.tau * x_dot\n",
    "        x_dot = x_dot + env.tau * xacc\n",
    "        theta = theta + env.tau * theta_dot\n",
    "        theta_dot = theta_dot + env.tau * thetaacc\n",
    "    else:  # semi-implicit euler\n",
    "        x_dot = x_dot + env.tau * xacc\n",
    "        x = x + env.tau * x_dot\n",
    "        theta_dot = theta_dot + env.tau * thetaacc\n",
    "        theta = theta + env.tau * theta_dot\n",
    "\n",
    "    return np.array([x, x_dot, theta, theta_dot])\n",
    "\n",
    "env = gym.make('CartPoleContinuous-v0').env\n",
    "\n",
    "obs = env.reset()\n",
    "ddp = DDP(lambda x, u: dynamics(env, x, u),  # x(i+1) = f(x(i), u)\n",
    "          lambda x, u: 0.5 * np.sum(np.square(u)),  # l(x, u)\n",
    "          lambda x: 0.5 * \\\n",
    "          (np.square(1.0 - np.cos(x[2])) + \\\n",
    "           np.square(x[1]) + np.square(x[3])),  # lf(x)\n",
    "          env.force_max,\n",
    "          env.observation_space.shape[0])\n",
    "u_seq = [np.zeros(1) for _ in range(ddp.pred_time)]\n",
    "x_seq = [obs[0]]\n",
    "\n",
    "for t in range(ddp.pred_time):\n",
    "    x_seq.append(dynamics(env, x_seq[-1], u_seq[t]))\n",
    "\n",
    "cnt = 0\n",
    "while True:\n",
    "    #env.render()\n",
    "    #import pyglet\n",
    "    #pyglet.image.get_buffer_manager().get_color_buffer().save('frame_%04d.png' % cnt)\n",
    "    for _ in range(3):\n",
    "        k_seq, kk_seq = ddp.backward(x_seq, u_seq)\n",
    "        x_seq, u_seq = ddp.forward(x_seq, u_seq, k_seq, kk_seq)\n",
    "\n",
    "    print(u_seq.T)\n",
    "    obs, _, _, _ = env.step(u_seq[0])\n",
    "    x_seq[0] = obs.copy()\n",
    "    cnt += 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
